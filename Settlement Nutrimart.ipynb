{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Masterdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oke lets go\n",
      "D:\\1. Masterdata\\Clean Data/data_all_23 August With Order Online.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (1,15,24,25,27,29,32,35,37,39,53,54,57,59,60,66,67,73,74,80,81,87,88,94,101,108,109,113,122,134,135,136,142,167,168,172,173,174,176,180,181,183,196,197,198,199,200,201,202,203,205,209,210,211,212,213,214,218,226,229,234,235,236,237,238,239,240,241,242,243) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "### run 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print('oke lets go')\n",
    "\n",
    "list_of_files=os.listdir(r\"D:\\1. Masterdata\\Clean Data\")\n",
    "a=[r\"D:\\1. Masterdata\\Clean Data/\"+i for i in list_of_files]\n",
    "latest_file = max(a, key=os.path.getctime)\n",
    "print(latest_file)\n",
    "\n",
    "data_all = pd.read_csv(latest_file, sep = ';',converters = {'Phone' : str, 'Order #' : str, 'AWB' : str})\n",
    "data_all['Phone'] = data_all['Phone'].astype(str).str.replace('=\"', '', regex = False)\n",
    "data_all['Phone'] = data_all['Phone'].astype(str).str.replace('\"', '', regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbundling\n",
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\frame.py:9203: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Price List NFI_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  validate=validate,\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 2\n",
    "real_sku = ['2101481443P8']\n",
    "\n",
    "temp2 = data_all[\n",
    "    (data_all['Real SKU'].isin(real_sku))\n",
    "]\n",
    "\n",
    "temp2 = temp2.drop('Real SKU_y', axis = 1)\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "    \n",
    "data_SKU = pd.read_excel(r\"D:\\1. Masterdata\\SKU_File\\data_SKU.xlsx\")\n",
    "\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ttnmecom24'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\", 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "if os.path.isfile(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\") :    \n",
    "    SKU_append = pd.read_excel(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\")\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "to_excel = data_SKU.to_excel(r\"D:\\1. Masterdata\\SKU_File\\data_SKU.xlsx\", index = False)\n",
    "\n",
    "data_SKU.loc[data_SKU['Price List NFI'].isin(['-']), 'Price List NFI'] = 0\n",
    "data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "\n",
    "data_SKU['Real SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)    \n",
    "\n",
    "list_col = ['Real SKU', 'Real Nama Produk']\n",
    "\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp2.index)\n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "\n",
    "list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp2.index)\n",
    "list_pcs = [x for x in temp_merge.columns if 'PCS' in x and '_y' in x]\n",
    "for i in list_pcs:\n",
    "    temp_merge[i] = temp_merge[i] * temp_merge['Qty. Invoiced']\n",
    "\n",
    "list_col = data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()    \n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "    \n",
    "    \n",
    "print(\"Unbundling\")\n",
    "data_bundle1 = temp2[~temp2['Produk 1'].isnull()]\n",
    "data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle2 = temp2[~temp2['Produk 2'].isnull()]\n",
    "data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle3 = temp2[~temp2['Produk 3'].isnull()]\n",
    "data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle4 = temp2[~temp2['Produk 4'].isnull()]\n",
    "data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle5 = temp2[~temp2['Produk 5'].isnull()]\n",
    "data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle6 = temp2[~temp2['Produk 6'].isnull()]\n",
    "data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle7 = temp2[~temp2['Produk 7'].isnull()]\n",
    "data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "print(\"Pricing\")\n",
    "temp2 = temp2.append(data_bundle, ignore_index = True, sort = False)\n",
    "list_col = ['Real SKU', 'Price List NFI', 'Harga Cost']\n",
    "\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp2.index)\n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "    \n",
    "temp2['Price List NFI'] = pd.to_numeric(temp2['Price List NFI']).astype(int)\n",
    "temp2['Harga Cost'] = pd.to_numeric(temp2['Harga Cost']).astype(int)\n",
    "temp2['Qty. Invoiced'] = pd.to_numeric(temp2['Qty. Invoiced']).astype(int)\n",
    "\n",
    "temp2['Total Net'] = temp2['Price List NFI'] * temp2['Qty. Invoiced']\n",
    "temp2['Total Harga Cost'] = temp2['Harga Cost'] * temp2['Qty. Invoiced']\n",
    "\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "temp2['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "temp2['Total'][temp.index] = temp['Total']\n",
    "temp2['Subtotal'][temp.index] = temp['Subtotal']\n",
    "\n",
    "temp2['Order #'] = temp2['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp2['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "temp = temp2[temp2['Bundle Name'].isnull()]\n",
    "temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "temp = temp2.merge(temp_group, how = 'left', on = 'Order #').set_index(temp2.index)\n",
    "temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "temp2['Shipping'][temp.index] = temp['Shipping_y']\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp2['Shipping'][temp.index] = temp['Shipping']\n",
    "\n",
    "indeks = data_all[(data_all['Real SKU'].isin(real_sku)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))].index.to_list()\n",
    "prod_name = data_all[(data_all['Real SKU'].isin(real_sku)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))]['Product Name'].unique()\n",
    "\n",
    "data_all = data_all.drop(indeks, axis = 0)\n",
    "\n",
    "indeks = data_all[(data_all['Bundle Name'].isin(prod_name)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))].index.to_list()\n",
    "\n",
    "data_all = data_all.drop(indeks, axis = 0)\n",
    "# data_all = data_all.reset_index(drop = True)\n",
    "# orders = temp2['Order #'].unique()\n",
    "\n",
    "# data_all = data_all.drop(indeks, axis = 0)\n",
    "data_all = data_all.append(temp2, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbundling\n",
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:159: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:160: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:161: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 3\n",
    "real_sku = ['2104523105P3']\n",
    "\n",
    "temp2 = data_all[\n",
    "    (data_all['Real SKU'].isin(real_sku))\n",
    "]\n",
    "\n",
    "temp2 = temp2.drop('Real SKU_y', axis = 1)\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "    \n",
    "data_SKU = pd.read_excel(r\"D:\\1. Masterdata\\SKU_File\\data_SKU.xlsx\")\n",
    "\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ttnmecom24'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\", 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "if os.path.isfile(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\") :    \n",
    "    SKU_append = pd.read_excel(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\")\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "to_excel = data_SKU.to_excel(r\"D:\\1. Masterdata\\SKU_File\\data_SKU.xlsx\", index = False)\n",
    "\n",
    "data_SKU.loc[data_SKU['Price List NFI'].isin(['-']), 'Price List NFI'] = 0\n",
    "data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "\n",
    "data_SKU['Real SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)    \n",
    "\n",
    "list_col = ['Real SKU', 'Real Nama Produk']\n",
    "\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp2.index)\n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "\n",
    "list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp2.index)\n",
    "list_pcs = [x for x in temp_merge.columns if 'PCS' in x and '_y' in x]\n",
    "for i in list_pcs:\n",
    "    temp_merge[i] = temp_merge[i] * temp_merge['Qty. Invoiced']\n",
    "\n",
    "list_col = data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()    \n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "    \n",
    "    \n",
    "print(\"Unbundling\")\n",
    "data_bundle1 = temp2[~temp2['Produk 1'].isnull()]\n",
    "data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle2 = temp2[~temp2['Produk 2'].isnull()]\n",
    "data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle3 = temp2[~temp2['Produk 3'].isnull()]\n",
    "data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle4 = temp2[~temp2['Produk 4'].isnull()]\n",
    "data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle5 = temp2[~temp2['Produk 5'].isnull()]\n",
    "data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle6 = temp2[~temp2['Produk 6'].isnull()]\n",
    "data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle7 = temp2[~temp2['Produk 7'].isnull()]\n",
    "data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "print(\"Pricing\")\n",
    "temp2 = temp2.append(data_bundle, ignore_index = True, sort = False)\n",
    "list_col = ['Real SKU', 'Price List NFI', 'Harga Cost']\n",
    "\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp2.index)\n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "    \n",
    "temp2['Price List NFI'] = pd.to_numeric(temp2['Price List NFI']).astype(int)\n",
    "temp2['Harga Cost'] = pd.to_numeric(temp2['Harga Cost']).astype(int)\n",
    "temp2['Qty. Invoiced'] = pd.to_numeric(temp2['Qty. Invoiced']).astype(int)\n",
    "\n",
    "temp2['Total Net'] = temp2['Price List NFI'] * temp2['Qty. Invoiced']\n",
    "temp2['Total Harga Cost'] = temp2['Harga Cost'] * temp2['Qty. Invoiced']\n",
    "\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "temp2['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "temp2['Total'][temp.index] = temp['Total']\n",
    "temp2['Subtotal'][temp.index] = temp['Subtotal']\n",
    "\n",
    "temp2['Order #'] = temp2['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp2['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "temp = temp2[temp2['Bundle Name'].isnull()]\n",
    "temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "temp = temp2.merge(temp_group, how = 'left', on = 'Order #').set_index(temp2.index)\n",
    "temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "temp2['Shipping'][temp.index] = temp['Shipping_y']\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp2['Shipping'][temp.index] = temp['Shipping']\n",
    "\n",
    "indeks = data_all[(data_all['Real SKU'].isin(real_sku)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))].index.to_list()\n",
    "prod_name = data_all[(data_all['Real SKU'].isin(real_sku)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))]['Product Name'].unique()\n",
    "\n",
    "data_all = data_all.drop(indeks, axis = 0)\n",
    "\n",
    "indeks = data_all[(data_all['Bundle Name'].isin(prod_name)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))].index.to_list()\n",
    "\n",
    "data_all = data_all.drop(indeks, axis = 0)\n",
    "# data_all = data_all.reset_index(drop = True)\n",
    "# orders = temp2['Order #'].unique()\n",
    "\n",
    "# data_all = data_all.drop(indeks, axis = 0)\n",
    "data_all = data_all.append(temp2, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbundling\n",
      "Pricing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#### run 4\n",
    "real_sku = ['1101978453P4']\n",
    "\n",
    "temp2 = data_all[\n",
    "    (data_all['Real SKU'].isin(real_sku))\n",
    "]\n",
    "\n",
    "temp2 = temp2.drop('Real SKU_y', axis = 1)\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "    \n",
    "data_SKU = pd.read_excel(r\"D:\\1. Masterdata\\SKU_File\\data_SKU.xlsx\")\n",
    "\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ttnmecom24'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\", 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "if os.path.isfile(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\") :    \n",
    "    SKU_append = pd.read_excel(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\")\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "\n",
    "to_excel = data_SKU.to_excel(r\"D:\\1. Masterdata\\SKU_File\\data_SKU.xlsx\", index = False)\n",
    "\n",
    "data_SKU.loc[data_SKU['Price List NFI'].isin(['-']), 'Price List NFI'] = 0\n",
    "data_SKU['Price List NFI'] = data_SKU['Price List NFI'].astype(float).astype('int64')\n",
    "\n",
    "data_SKU['Real SKU'] = data_SKU['SKU'].astype(str).str.replace('(S)', '', regex = False)\n",
    "data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)    \n",
    "\n",
    "list_col = ['Real SKU', 'Real Nama Produk']\n",
    "\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp2.index)\n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "\n",
    "list_col = ['SKU'] + data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['SKU']), how = 'left', left_on = 'Real SKU', right_on = 'SKU').set_index(temp2.index)\n",
    "list_pcs = [x for x in temp_merge.columns if 'PCS' in x and '_y' in x]\n",
    "for i in list_pcs:\n",
    "    temp_merge[i] = temp_merge[i] * temp_merge['Qty. Invoiced']\n",
    "\n",
    "list_col = data_SKU.columns[data_SKU.columns.get_loc('Produk 1'):data_SKU.columns.get_loc('Harga Organik 7')+1].to_list()    \n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "    \n",
    "    \n",
    "print(\"Unbundling\")\n",
    "data_bundle1 = temp2[~temp2['Produk 1'].isnull()]\n",
    "data_bundle1['Bundle Name'] = data_bundle1['Product Name']\n",
    "data_bundle1['Product Name'] = data_bundle1['Produk 1']\n",
    "data_bundle1['SKU'] = data_bundle1['SKU Produk 1']\n",
    "data_bundle1['Qty. Invoiced'] = data_bundle1['PCS Produk 1']\n",
    "data_bundle1['Price List NFI'] = data_bundle1['Price List NFI 1']\n",
    "data_bundle1['Total Net'] = data_bundle1['Price List NFI 1']\n",
    "data_bundle1['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle2 = temp2[~temp2['Produk 2'].isnull()]\n",
    "data_bundle2['Bundle Name'] = data_bundle2['Product Name']\n",
    "data_bundle2['Product Name'] = data_bundle2['Produk 2']\n",
    "data_bundle2['SKU'] = data_bundle2['SKU Produk 2']\n",
    "data_bundle2['Qty. Invoiced'] = data_bundle2['PCS Produk 2']\n",
    "data_bundle2['Price List NFI'] = data_bundle2['Price List NFI 2']\n",
    "data_bundle2['Total Net'] = data_bundle2['Price List NFI 2'] \n",
    "data_bundle2['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle3 = temp2[~temp2['Produk 3'].isnull()]\n",
    "data_bundle3['Bundle Name'] = data_bundle3['Product Name']\n",
    "data_bundle3['Product Name'] = data_bundle3['Produk 3']\n",
    "data_bundle3['SKU'] = data_bundle3['SKU Produk 3']\n",
    "data_bundle3['Qty. Invoiced'] = data_bundle3['PCS Produk 3']\n",
    "data_bundle3['Price List NFI'] = data_bundle3['Price List NFI 3']\n",
    "data_bundle3['Total Net'] = data_bundle3['Price List NFI 3'] \n",
    "data_bundle3['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle4 = temp2[~temp2['Produk 4'].isnull()]\n",
    "data_bundle4['Bundle Name'] = data_bundle4['Product Name']\n",
    "data_bundle4['Product Name'] = data_bundle4['Produk 4']\n",
    "data_bundle4['SKU'] = data_bundle4['SKU Produk 4']\n",
    "data_bundle4['Qty. Invoiced'] = data_bundle4['PCS Produk 4']\n",
    "data_bundle4['Price List NFI'] = data_bundle4['Price List NFI 4']\n",
    "data_bundle4['Total Net'] = data_bundle4['Price List NFI 4'] \n",
    "data_bundle4['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle5 = temp2[~temp2['Produk 5'].isnull()]\n",
    "data_bundle5['Bundle Name'] = data_bundle5['Product Name']\n",
    "data_bundle5['Product Name'] = data_bundle5['Produk 5']\n",
    "data_bundle5['SKU'] = data_bundle5['SKU Produk 5']\n",
    "data_bundle5['Qty. Invoiced'] = data_bundle5['PCS Produk 5']\n",
    "data_bundle5['Price List NFI'] = data_bundle5['Price List NFI 5']\n",
    "data_bundle5['Total Net'] = data_bundle5['Price List NFI 5']\n",
    "data_bundle5['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle6 = temp2[~temp2['Produk 6'].isnull()]\n",
    "data_bundle6['Bundle Name'] = data_bundle6['Product Name']\n",
    "data_bundle6['Product Name'] = data_bundle6['Produk 6']\n",
    "data_bundle6['SKU'] = data_bundle6['SKU Produk 6']\n",
    "data_bundle6['Qty. Invoiced'] = data_bundle6['PCS Produk 6']\n",
    "data_bundle6['Price List NFI'] = data_bundle6['Price List NFI 6']\n",
    "data_bundle6['Total Net'] = data_bundle6['Price List NFI 6']\n",
    "data_bundle6['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle7 = temp2[~temp2['Produk 7'].isnull()]\n",
    "data_bundle7['Bundle Name'] = data_bundle7['Product Name']\n",
    "data_bundle7['Product Name'] = data_bundle7['Produk 7']\n",
    "data_bundle7['SKU'] = data_bundle7['SKU Produk 7']\n",
    "data_bundle7['Qty. Invoiced'] = data_bundle7['PCS Produk 7']\n",
    "data_bundle7['Price List NFI'] = data_bundle7['Price List NFI 7']\n",
    "data_bundle7['Total Net'] = data_bundle7['Price List NFI 7']\n",
    "data_bundle7['Bundle Flag'] = np.nan\n",
    "\n",
    "data_bundle = data_bundle1.append([data_bundle2, data_bundle3, data_bundle4, data_bundle5, data_bundle6, data_bundle7], ignore_index = True, sort = False)\n",
    "data_bundle['SKU'] = data_bundle['SKU'].astype(str)\n",
    "data_bundle['SKU'] = data_bundle['SKU'].str.replace('\\.0$', '', regex = True)\n",
    "data_bundle[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']] = data_bundle.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU')[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y']]\n",
    "\n",
    "print(\"Pricing\")\n",
    "temp2 = temp2.append(data_bundle, ignore_index = True, sort = False)\n",
    "list_col = ['Real SKU', 'Price List NFI', 'Harga Cost']\n",
    "\n",
    "temp_merge = temp2.merge(data_SKU[list_col].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(temp2.index)\n",
    "for i in list_col:\n",
    "    temp2[i] = temp_merge[str(i) + '_y']\n",
    "    \n",
    "temp2['Price List NFI'] = pd.to_numeric(temp2['Price List NFI']).astype(int)\n",
    "temp2['Harga Cost'] = pd.to_numeric(temp2['Harga Cost']).astype(int)\n",
    "temp2['Qty. Invoiced'] = pd.to_numeric(temp2['Qty. Invoiced']).astype(int)\n",
    "\n",
    "temp2['Total Net'] = temp2['Price List NFI'] * temp2['Qty. Invoiced']\n",
    "temp2['Total Harga Cost'] = temp2['Harga Cost'] * temp2['Qty. Invoiced']\n",
    "\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Subtotal', 'Total']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Total'][list_nobundle.index] = list_nobundle['Total_y']\n",
    "temp2['Subtotal'][list_nobundle.index] = list_nobundle['Subtotal_y']\n",
    "\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Subtotal'] = temp['Subtotal'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp['Selling Price'] = temp['Subtotal']/temp['Qty. Invoiced']\n",
    "temp['Total'] = temp['Total'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "temp2['Total'][temp.index] = temp['Total']\n",
    "temp2['Subtotal'][temp.index] = temp['Subtotal']\n",
    "\n",
    "temp2['Order #'] = temp2['Order #'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Seller Discount']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Seller Discount'][list_nobundle.index] = list_nobundle['Seller Discount_y']\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Seller Discount'] = temp['Seller Discount'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp2['Seller Discount'][temp.index] = temp['Seller Discount']\n",
    "\n",
    "\n",
    "temp = temp2[temp2['Bundle Name'].isnull()]\n",
    "temp_group = temp[['Order #','Shipping']].groupby(['Order #']).sum().reset_index()\n",
    "\n",
    "temp = temp2.merge(temp_group, how = 'left', on = 'Order #').set_index(temp2.index)\n",
    "temp['Shipping_x'] = temp['Shipping_y'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "\n",
    "temp2['Shipping'][temp.index] = temp['Shipping_y']\n",
    "list_bundle = temp2[temp2['Bundle Flag'] == 'Bundle'][['Order #', 'Product Name', 'Shipping']].groupby(['Order #', 'Product Name']).sum().reset_index()\n",
    "list_nobundle = temp2[temp2['Bundle Name'].notnull()]\n",
    "list_nobundle = list_nobundle.merge(list_bundle, how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(list_nobundle.index)\n",
    "list_nobundle\n",
    "\n",
    "temp2['Shipping'][list_nobundle.index] = list_nobundle['Shipping_y']\n",
    "temp = temp2[temp2['Bundle Name'].notnull()]\n",
    "temp['Shipping'] = temp['Shipping'] * temp['Total Harga Cost']/temp.groupby(['Order #', 'Bundle Name'])['Total Harga Cost'].transform('sum')\n",
    "temp2['Shipping'][temp.index] = temp['Shipping']\n",
    "\n",
    "indeks = data_all[(data_all['Real SKU'].isin(real_sku)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))].index.to_list()\n",
    "prod_name = data_all[(data_all['Real SKU'].isin(real_sku)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))]['Product Name'].unique()\n",
    "\n",
    "data_all = data_all.drop(indeks, axis = 0)\n",
    "\n",
    "indeks = data_all[(data_all['Bundle Name'].isin(prod_name)) & \n",
    "                  (data_all['Order #'].isin(temp2['Order #'].unique()))].index.to_list()\n",
    "\n",
    "data_all = data_all.drop(indeks, axis = 0)\n",
    "# data_all = data_all.reset_index(drop = True)\n",
    "# orders = temp2['Order #'].unique()\n",
    "\n",
    "# data_all = data_all.drop(indeks, axis = 0)\n",
    "data_all = data_all.append(temp2, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run 5\n",
    "indeks = data_all[data_all['Bundle Name'].isin(\n",
    "    ['Tropicana Slim Gula Jawa 350ml','Tropicana Slim Hokkaido Cheese Cookies (5 Sch)']\n",
    ")].index.to_list()\n",
    "data_all = data_all.drop(indeks, axis = 0)\n",
    "data_all = data_all.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_cp=data_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=data_all_cp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for display\n",
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## run 5.1 skip udh di unbundling masterdata\n",
    "j_conv = pd.read_excel(\"Settlement Project\\Rumus Realisasi.xlsx\", sheet_name = 'Paket Brand')\n",
    "j_conv = j_conv.iloc[:,:5]\n",
    "j_conv = j_conv.rename(columns = {'SKU' : 'Real SKU', 'SKU.1' : 'SKU Produk'})\n",
    "j_conv = j_conv[j_conv['Real SKU'].notnull()]\n",
    "j_conv['SKU Produk'] = j_conv['SKU Produk'].astype(str).str.replace('.0', '',regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bundlenamejtipen=data_all[data_all['Real SKU'].isin(j_conv['Real SKU'].unique())]['Real Nama Produk'].unique()\n",
    "data_all=data_all[~data_all['Bundle Name'].isin(bundlenamejtipen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start\n",
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "A\n",
      "A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 6 skip udh di unbundling masterdata\n",
    "j_conv = pd.read_excel(\"Settlement Project\\Rumus Realisasi.xlsx\", sheet_name = 'Paket Brand')\n",
    "j_conv = j_conv.iloc[:,:5]\n",
    "j_conv = j_conv.rename(columns = {'SKU' : 'Real SKU', 'SKU.1' : 'SKU Produk'})\n",
    "j_conv = j_conv[j_conv['Real SKU'].notnull()]\n",
    "j_conv['SKU Produk'] = j_conv['SKU Produk'].astype(str).str.replace('.0', '',regex = False)\n",
    "\n",
    "print('start')\n",
    "temp_all = data_all.copy()\n",
    "print('start')\n",
    "temp_all['Real SKU'] = temp_all['Real SKU'].astype(str)\n",
    "j_conv['Real SKU'] = j_conv['Real SKU'].astype(str)\n",
    "\n",
    "temp_all = temp_all.merge(j_conv, how = 'left', on = 'Real SKU')\n",
    "print('start')\n",
    "paket_j = temp_all[temp_all['SKU Produk'].notnull()]\n",
    "\n",
    "paket_j['Bundle Name'] = paket_j['Product Name']\n",
    "paket_j['Product Name'] = paket_j['Name']\n",
    "paket_j['SKU'] = paket_j['SKU Produk']\n",
    "paket_j['Qty. Invoiced'] = paket_j['Qty. Invoiced'] * paket_j['Konversi ke UOM'].astype(float)\n",
    "paket_j['Bundle Flag'] = np.nan\n",
    "print('start')\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import smtplib \n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from smtplib import SMTP\n",
    "import smtplib\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "    \n",
    "\n",
    "print('A')\n",
    "data_SKU = pd.read_excel(r\"D:\\1. Masterdata\\SKU_File\\data_SKU.xlsx\")\n",
    "print('A')\n",
    "s = requests.Session()\n",
    "s.get(\"https://tatanama.pythonanywhere.com\")\n",
    "s.post(\"https://tatanama.pythonanywhere.com\", data = {'username' : 'ecommerce', 'password' : 'ttnmecom24'})\n",
    "r = s.get(\"https://tatanama.pythonanywhere.com/download\")\n",
    "\n",
    "with open(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\", 'wb') as output:\n",
    "    output.write(r.content)\n",
    "\n",
    "if os.path.isfile(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\") :    \n",
    "    SKU_append = pd.read_excel(r\"D:\\1. Masterdata\\SKU_File\\Master tatanama.xlsx\")\n",
    "    SKU_append.columns = [x.replace('_', ' ') for x in SKU_append.columns]\n",
    "    data_SKU = data_SKU[~data_SKU['SKU'].astype(str).isin(SKU_append['SKU'].astype(str))]\n",
    "    data_SKU = data_SKU.append(SKU_append, ignore_index = True, sort = False)\n",
    "    \n",
    "data_SKU['Real SKU'] = data_SKU['SKU'].astype(str)\n",
    "data_SKU['Real Nama Produk'] = data_SKU['Nama Produk'].astype(str)\n",
    "if 'Real SKU_y' in paket_j.columns:\n",
    "    paket_j = paket_j.drop('Real SKU_y', axis = 1)\n",
    "paket_j['SKU'] = paket_j['SKU'].astype(str)\n",
    "paket_j[['Real SKU', 'Real Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU', 'Price List NFI']] = paket_j.merge(data_SKU[['Real SKU', 'Nama Produk', 'Brand', 'Sub Brand', 'Parent Item', 'Parent SKU', 'Price List NFI']].drop_duplicates(['Real SKU']), how = 'left', left_on = 'SKU', right_on = 'Real SKU').set_index(paket_j.index)[['Real SKU_y', 'Nama Produk', 'Brand_y', 'Sub Brand_y', 'Parent Item_y', 'Parent SKU_y', 'Price List NFI_y']]\n",
    "\n",
    "paket_j['Price List NFI']=paket_j['Price List NFI'].astype(int)\n",
    "paket_j['Total Net'] = paket_j['Price List NFI'] * paket_j['Qty. Invoiced']\n",
    "\n",
    "paket_j['Subtotal'] = paket_j['Subtotal'] * paket_j['Total Net']/paket_j.groupby(['Order #', 'Bundle Name'])['Total Net'].transform('sum')\n",
    "paket_j['Selling Price'] = paket_j['Subtotal']/paket_j['Qty. Invoiced']\n",
    "paket_j['Total'] = paket_j['Total'] * paket_j['Total Net']/paket_j.groupby(['Order #', 'Bundle Name'])['Total Net'].transform('sum')\n",
    "\n",
    "paket_j['Seller Discount'] = paket_j['Seller Discount'] * paket_j['Total Net']/paket_j.groupby(['Order #', 'Bundle Name'])['Total Net'].transform('sum')\n",
    "paket_j['Shipping'] = paket_j['Shipping'] * paket_j['Total Net']/paket_j.groupby(['Order #', 'Bundle Name'])['Total Net'].transform('sum')\n",
    "\n",
    "paket_j = paket_j.drop(['Nama Paket', 'SKU Produk', 'Name', 'Konversi ke UOM'], axis = 1)\n",
    "data_all = data_all.append(paket_j, ignore_index = True, sort = False)\n",
    "indeks = data_all[data_all['Product Name'].isin(paket_j['Bundle Name'])].index.to_list()\n",
    "data_all['Brand'][indeks] = 'Bundle'\n",
    "\n",
    "data_all['PL Before PPN'] = data_all['Price List NFI']/1.11\n",
    "data_all['Total Net Before PPN'] = data_all['PL Before PPN'] * data_all['Qty. Invoiced']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\series.py:1135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._set_values(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "### run 7 change date\n",
    "nutrimart = data_all[(data_all['Store'] == 'Nutrimart')&\n",
    "                     (data_all['Channel']!='WhatsApp')\n",
    "                     & (data_all['Year'] > 2021)\n",
    "                    & (data_all['True datetime'] < '2024-08-27')]\n",
    "\n",
    "indeks = nutrimart[(nutrimart['Real SKU'].astype(str).str.contains('^\\(B\\)', regex = True)) &\n",
    "      (~nutrimart['Brand'].isin(['Bonus Produk', 'Gimmick']))].index.to_list()\n",
    "\n",
    "nutrimart['Brand'][indeks] = 'Bonus Produk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopify=pd.read_csv(r\"D:\\Downloads\\orders_export_1 (3).csv\")\n",
    "shopify['Shipping BS']=shopify['Shipping']\n",
    "shopify=shopify[shopify['Payment References'].notnull()][['Name','Financial Status','Fulfillment Status','Payment ID','Payment References','Shipping BS']].drop_duplicates('Payment References')\n",
    "# shopify.head(5)\n",
    "shopify['Order #']=shopify['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge shopify\n"
     ]
    }
   ],
   "source": [
    "if 'Payment References' not in nutrimart.columns:\n",
    "    print('merge shopify')\n",
    "    nutrimart=nutrimart.merge(shopify[['Order #','Payment ID','Payment References','Shipping BS']],how='left')\n",
    "    nutrimart.loc[nutrimart['Shipping BS'].notnull(),'Shipping']=nutrimart.loc[nutrimart['Shipping BS'].notnull()]['Shipping BS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shopify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Seller Centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_sales_detailed_report_317285.csv\n",
      "export_sales_detailed_report_317286.csv\n",
      "export_sales_detailed_report_317287.csv\n",
      "export_sales_detailed_report_317288.csv\n",
      "export_sales_detailed_report_317289.csv\n",
      "export_sales_detailed_report_317290.csv\n",
      "export_sales_detailed_report_317291.csv\n",
      "export_sales_detailed_report_317292.csv\n",
      "export_sales_detailed_report_317293.csv\n",
      "export_sales_detailed_report_317294.csv\n",
      "Nutrimart Seller Centre Details 1-28 Feb 2022.csv\n",
      "Nutrimart Seller Centre Details 1-30 Nov.csv\n",
      "Nutrimart Seller Centre Details 1-31 Des.csv\n",
      "Nutrimart Seller Centre Details 1-31 Jan 2022.csv\n",
      "Nutrimart Seller Centre Details 1-31 Mar 2022.csv\n",
      "Nutrimart Seller Centre Details 1-31 Oct.csv\n",
      "10674\n",
      "10674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "### run 8\n",
    "selcen = pd.DataFrame()\n",
    "\n",
    "for i in os.listdir('Settlement Project/Nutrimart/Detail Salah/'):\n",
    "    print(i)\n",
    "    temp = pd.read_csv('Settlement Project/Nutrimart/Detail Salah/' + str(i), index_col = False)\n",
    "    selcen = selcen.append(temp, ignore_index = True, sort = False)\n",
    "    \n",
    "selcen['Order #'] = selcen['Order #'].astype(str)\n",
    "selcen['Status Seller Centre'] = selcen['Order Status']\n",
    "selcen['Total Selcen'] = selcen['Subtotal']\n",
    "selcen['Order Date Selcen'] = selcen['Order date']\n",
    "selcen['SKU'] = selcen['SKU'].astype(str).str.split('-', expand = True)[0]\n",
    "selcen['Selling Price'] = selcen['Item Cost']\n",
    "selcen['Product Name'] = selcen['Product Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "selcen['Bundle Name'] = selcen['Bundle Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "\n",
    "nutrimart['Order #'] = nutrimart['Order #'].astype(str)\n",
    "nutrimart['Order #'] = nutrimart['Order #'].astype(str)\n",
    "nutrimart['Product Name'] = nutrimart['Product Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "nutrimart['Bundle Name'] = nutrimart['Bundle Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "nutrimart['SKU'] = nutrimart['SKU'].astype(str)\n",
    "\n",
    "print(len(nutrimart))\n",
    "nutrimart_merge = nutrimart.merge(selcen.drop_duplicates()[['Order #', 'Product Name', 'Bundle Name', 'SKU', 'Selling Price', 'Order Date Selcen', 'Status Seller Centre', 'Total Selcen']].drop_duplicates(), how = 'left', on = ['Order #', 'Product Name', 'Bundle Name', 'SKU', 'Selling Price'])\n",
    "print(len(nutrimart_merge))\n",
    "\n",
    "null_status = nutrimart_merge[nutrimart_merge['Status Seller Centre'].isnull()]\n",
    "null_status = null_status.merge(selcen.drop_duplicates()[['Order #', 'Product Name', 'Bundle Name', 'SKU', 'Order Date Selcen', 'Status Seller Centre', 'Total Selcen']].drop_duplicates(['Order #', 'Product Name', 'Bundle Name', 'SKU']), how = 'left', on = ['Order #', 'Product Name', 'Bundle Name', 'SKU']).set_index(null_status.index)\n",
    "\n",
    "nutrimart_merge['Order Date Selcen'][null_status.index] = null_status['Order Date Selcen_y']\n",
    "nutrimart_merge['Status Seller Centre'][null_status.index] = null_status['Status Seller Centre_y']\n",
    "nutrimart_merge['Total Selcen'][null_status.index] = null_status['Total Selcen_y']\n",
    "\n",
    "null_status = nutrimart_merge[nutrimart_merge['Status Seller Centre'].isnull()]\n",
    "null_status = null_status.merge(selcen.drop_duplicates()[['Order #', 'Product Name', 'Bundle Name', 'Order Date Selcen', 'Status Seller Centre', 'Total Selcen']].drop_duplicates(['Order #', 'Product Name', 'Bundle Name']), how = 'left', on = ['Order #', 'Product Name', 'Bundle Name']).set_index(null_status.index)\n",
    "\n",
    "nutrimart_merge['Order Date Selcen'][null_status.index] = null_status['Order Date Selcen_y']\n",
    "nutrimart_merge['Status Seller Centre'][null_status.index] = null_status['Status Seller Centre_y']\n",
    "nutrimart_merge['Total Selcen'][null_status.index] = null_status['Total Selcen_y']\n",
    "\n",
    "indeks = nutrimart_merge[nutrimart_merge['Bundle Name'] == 'nan'].index.to_list()\n",
    "nutrimart_merge['Bundle Name'][indeks] = np.nan\n",
    "\n",
    "null_status = nutrimart_merge[nutrimart_merge['Status Seller Centre'].isnull()]\n",
    "null_status = null_status.merge(selcen.drop_duplicates()[['Order #', 'Product Name', 'Bundle Name', 'Order Date Selcen', 'Status Seller Centre', 'Total Selcen']].drop_duplicates(['Order #', 'Product Name', 'Bundle Name']), how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(null_status.index)\n",
    "\n",
    "null_status['Total Selcen_y'] = null_status['Total Selcen_y'].fillna(0) * null_status['Total Net Before PPN']/null_status.groupby(['Order #', 'Bundle Name_x'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_merge['Order Date Selcen'][null_status.index] = null_status['Order Date Selcen_y']\n",
    "nutrimart_merge['Status Seller Centre'][null_status.index] = null_status['Status Seller Centre_y']\n",
    "nutrimart_merge['Total Selcen'][null_status.index] = null_status['Total Selcen_y']\n",
    "\n",
    "indeks = nutrimart_merge[nutrimart_merge['Bundle Name'] == 'nan'].index.to_list()\n",
    "nutrimart_merge['Bundle Name'][indeks] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Seller Centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for display\n",
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Bundle Name</th>\n",
       "      <th>Order #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Product Name, SKU, Bundle Name, Order #]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### run 9\n",
    "nutrimart_merge[(nutrimart_merge['Order #'].isin(selcen['Order #'])) & \n",
    "              (nutrimart_merge['Status Seller Centre'].isnull())\n",
    "             ].groupby(['Product Name', 'SKU', 'Bundle Name'], dropna = False)['Order #'].first().reset_index()\n",
    "\n",
    "##harus kosong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Gudang E-Commerce Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pypyodbc\n",
    "\n",
    "conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "                        'Server=NFI-DB-01;'\n",
    "                        'Database=gudang;'\n",
    "                        # 'UID=andra.miftah;'\n",
    "                        # 'PWD=24nutrifoodindonesia21;'\n",
    "                        'Trusted_Connection=yes;'\n",
    "                )\n",
    "\n",
    "cursor = conn.cursor()\n",
    "wms_telkom = pd.read_sql(r\"\"\"SELECT t1.id, t1.order_id,t1.status, t1.quantity, t1.product_id, t2.id,  t2.order_number, t2.invoice_number, t2.channel, t2.order_date, t3.id, t3.sku, t3.name\n",
    "  FROM [gudang].[dbo].[outbound_items] as t1\n",
    "  left join orders as t2\n",
    "  on t1.order_id = t2.id\n",
    "  left join products as t3\n",
    "  on t1.product_id = t3.id\"\"\", conn)\n",
    "\n",
    "wms_telkom_cp = wms_telkom.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 10 - alternative\n",
    "\n",
    "# wms_telkom=pd.read_excel(r\"D:\\6. settlement\\Code\\Settlement Project\\Manual\\backup wms\\data_wms_telkom 21 Apr 2023.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wms_telkom_cp.to_excel(r\"D:\\6. settlement\\Code\\Settlement Project\\Manual\\backup wms\\data_wms_telkom 1 Feb 2024.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for backup\n",
    "wms_telkom = wms_telkom_cp.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 11\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pypyodbc\n",
    "\n",
    "# conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "#                 'Server=NFI-DB-01;'\n",
    "#                 'Database=gudang;'\n",
    "#                 'UID=andra.miftah;'\n",
    "#                 'PWD=24nutrifoodindonesia21;'\n",
    "#                 )\n",
    "\n",
    "# cursor = conn.cursor()\n",
    "# wms_telkom = pd.read_sql(r\"\"\"SELECT t1.id, t1.order_id,t1.status, t1.quantity, t1.product_id, t2.id,  t2.order_number, t2.invoice_number, t2.channel, t2.order_date, t3.id, t3.sku, t3.name\n",
    "#   FROM [gudang].[dbo].[outbound_items] as t1\n",
    "#   left join orders as t2\n",
    "#   on t1.order_id = t2.id\n",
    "#   left join products as t3\n",
    "#   on t1.product_id = t3.id\"\"\", conn)\n",
    "\n",
    "# wms_telkom_cp = wms_telkom.copy()\n",
    "# wms_telkom = pd.read_csv(r'Backup WMS Telkom.csv', sep = ';')\n",
    "                         \n",
    "# outbound_items = pd.read_csv(r'Backup Gudang 4 Sept 2021 Gudang Baru/outbound_items.csv', sep = ';')\n",
    "# orders = pd.read_csv(r'Backup Gudang 4 Sept 2021 Gudang Baru/orders.csv', sep = ';')\n",
    "# products = pd.read_csv(r'Backup Gudang 4 Sept 2021 Gudang Baru/products.csv', sep = ';')\n",
    "\n",
    "# wms_telkom2 = outbound_items[['id', 'order_id','status', 'quantity', 'product_id']].merge(\n",
    "#     orders[['id',  'order_number', 'invoice_number', 'channel', 'order_date']], how = 'left', left_on = 'order_id', right_on = 'id'\n",
    "# ).merge(\n",
    "#     products[['id', 'sku', 'name']], how = 'left', left_on = 'product_id', right_on = 'id'\n",
    "# )\n",
    "wms_telkom = wms_telkom[wms_telkom['channel'].isin(['Nutrimart', 'Nutrimart '])]\n",
    "# wms_telkom2 = wms_telkom2[wms_telkom2['channel'].isin(['Nutrimart', 'Nutrimart '])]\n",
    "if 'STATUS' in wms_telkom.columns:\n",
    "    wms_telkom = wms_telkom.rename(columns = {'STATUS':'status'})\n",
    "wms_telkom = wms_telkom[['order_number','invoice_number', 'sku', 'status', 'quantity']]\n",
    "# wms_telkom2 = wms_telkom2[['order_number','invoice_number', 'sku', 'status', 'quantity']].drop_duplicates()\n",
    "\n",
    "wms_telkom['invoice_number'] = wms_telkom['invoice_number'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_telkom['order_number'] = wms_telkom['order_number'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_telkom['sku'] = wms_telkom['sku'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "# wms_telkom2['invoice_number'] = wms_telkom2['invoice_number'].astype(str).str.replace('.0', '', regex = False)\n",
    "# wms_telkom2['order_number'] = wms_telkom2['order_number'].astype(str).str.replace('.0', '', regex = False)\n",
    "# wms_telkom2['sku'] = wms_telkom2['sku'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "# wms_telkom = wms_telkom.append(wms_telkom2, ignore_index = True, sort = False)\n",
    "\n",
    "min1 = wms_telkom[wms_telkom['order_number'].astype(str).str.contains('-1')]\n",
    "min1['order_number'] = min1['order_number'].astype(str).str.replace('-1', '', regex = False)\n",
    "\n",
    "temp_telkom = wms_telkom.merge(min1, how = 'left', on = ['order_number', 'sku']).set_index(wms_telkom.index)\n",
    "indeks = temp_telkom[temp_telkom['invoice_number_y'].notnull()].index.to_list()\n",
    "wms_telkom = wms_telkom.drop(indeks, axis = 0)\n",
    "\n",
    "wms_telkom['order_number'] = wms_telkom['order_number'].astype(str).str.replace('-1', '', regex = False)\n",
    "# wms_telkom = wms_telkom.drop('order_number', axis = 1)\n",
    "min2 = wms_telkom[wms_telkom['order_number'].astype(str).str.contains('-2')]\n",
    "min2['order_number'] = min2['order_number'].astype(str).str.replace('-2', '', regex = False)\n",
    "\n",
    "temp_telkom = wms_telkom.merge(min2, how = 'left', on = ['order_number', 'sku']).set_index(wms_telkom.index)\n",
    "indeks = temp_telkom[temp_telkom['invoice_number_y'].notnull()].index.to_list()\n",
    "wms_telkom = wms_telkom.drop(indeks, axis = 0)\n",
    "\n",
    "wms_telkom['order_number'] = wms_telkom['order_number'].astype(str).str.replace('-2', '', regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 12\n",
    "wms_telkom['WH'] = 'Telkom'\n",
    "wms_telkom = wms_telkom.rename(columns = {'order_number' : 'Order #', 'status':'Outbound Status', 'sku' : 'SKU WH', 'quantity' : 'Outbound Qty'})\n",
    "\n",
    "colname = wms_telkom.columns.to_list()\n",
    "wms_telkom_all = wms_telkom.merge(j_conv, how = 'left', left_on = ['SKU WH'], right_on = ['Real SKU'])\n",
    "wms_j = wms_telkom_all[wms_telkom_all['SKU Produk'].notnull()]\n",
    "\n",
    "wms_j['SKU WH'] = wms_j['SKU Produk']\n",
    "wms_j['Outbound Qty'] = wms_j['Outbound Qty'] * wms_j['Konversi ke UOM'].astype(float)\n",
    "\n",
    "wms_telkom = wms_telkom.append(wms_j, ignore_index = True, sort = False)\n",
    "wms_telkom = wms_telkom[colname]\n",
    "\n",
    "wms_telkom = wms_telkom.groupby(['Order #','invoice_number', 'SKU WH', 'Outbound Status', 'WH'], dropna = False)['Outbound Qty'].sum().reset_index()\n",
    "\n",
    "temp_telkom = nutrimart_merge.copy()\n",
    "\n",
    "indeks = temp_telkom[(temp_telkom['Real SKU'] == '7300281') & (temp_telkom['Bundle Name'].isnull())].index.to_list()\n",
    "temp_telkom['Brand'][indeks] = 'Bundle'\n",
    "\n",
    "temp_telkom['Order #'] = temp_telkom['Order #'].astype(str)\n",
    "wms_telkom['Order #'] = wms_telkom['Order #'].astype(str)\n",
    "\n",
    "temp_telkom['Real SKU'] = temp_telkom['Real SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_telkom['SKU WH'] = wms_telkom['SKU WH'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "temp_telkom = temp_telkom.merge(wms_telkom.drop_duplicates(['Order #', 'SKU WH']), how = 'left', left_on = ['Order #', 'Real SKU'], right_on = ['Order #', 'SKU WH'])\n",
    "\n",
    "temp_telkom['Outbound Qty'] = temp_telkom['Outbound Qty'] * temp_telkom['Qty. Invoiced']/temp_telkom.groupby(['Order #', 'Real Nama Produk'])['Qty. Invoiced'].transform('sum')\n",
    "\n",
    "\n",
    "temp_telkom_bundle = temp_telkom[temp_telkom['Brand'] == 'Bundle']\n",
    "\n",
    "temp_buat_bundle = temp_telkom.groupby(['Order #', 'Bundle Name']).agg({'WH' : 'first', 'Outbound Status' : 'first', 'Outbound Qty' : 'max', 'Qty. Invoiced' : 'max'}).reset_index()\n",
    "temp_buat_bundle['Outbound Qty'] = temp_buat_bundle['Outbound Qty']/temp_buat_bundle['Qty. Invoiced']\n",
    "temp_buat_bundle = temp_buat_bundle.drop('Qty. Invoiced', axis = 1)\n",
    "\n",
    "temp_telkom_bundle = temp_telkom_bundle.merge(temp_buat_bundle.drop_duplicates(['Order #', 'Bundle Name']), how = 'left', left_on = ['Order #', 'Product Name'], right_on = ['Order #', 'Bundle Name']).set_index(temp_telkom_bundle.index)\n",
    "temp_telkom_bundle['Outbound Qty_y'] = temp_telkom_bundle['Outbound Qty_y']*temp_telkom_bundle['Qty. Invoiced']\n",
    "\n",
    "temp_telkom['Outbound Status'][temp_telkom_bundle.index] = temp_telkom_bundle['Outbound Status_y']\n",
    "temp_telkom['WH'][temp_telkom_bundle.index] = temp_telkom_bundle['WH_y']\n",
    "temp_telkom['Outbound Qty'][temp_telkom_bundle.index] = temp_telkom_bundle['Outbound Qty_y']\n",
    "\n",
    "nutrimart_wms = temp_telkom.copy()\n",
    "\n",
    "wms_copy = wms_telkom.copy()\n",
    "wms_copy['SKU WH'] = wms_copy['SKU WH'].astype(str).str.replace('2309005305', '2309005300')\n",
    "wms_copy['SKU WH'] = wms_copy['SKU WH'].astype(str).str.replace('F0302004001', '7300861')\n",
    "wms_copy['SKU WH'] = wms_copy['SKU WH'].astype(str).str.replace('F0302003003', '740070175')\n",
    "\n",
    "null_telkom = nutrimart_wms[(nutrimart_wms['WH'].isnull())\n",
    "            & (nutrimart_wms['Brand'] != 'Bundle') &\n",
    "            (nutrimart_wms['Order #'].isin(wms_telkom['Order #']))]\n",
    "\n",
    "null_telkom = null_telkom.drop(['WH', 'Outbound Status', 'Outbound Qty'], axis = 1)\n",
    "  \n",
    "null_telkom['Order #'] = null_telkom['Order #'].astype(str)\n",
    "wms_copy['Order #'] = wms_copy['Order #'].astype(str)\n",
    "\n",
    "null_telkom['Real SKU'] = null_telkom['Real SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_copy['SKU WH'] = wms_copy['SKU WH'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "null_telkom = null_telkom.merge(wms_copy.drop_duplicates(['Order #', 'SKU WH']), how = 'left', left_on = ['Order #', 'Real SKU'], right_on = ['Order #', 'SKU WH']).set_index(null_telkom.index)\n",
    "\n",
    "null_telkom_bundle = null_telkom[null_telkom['Brand'] == 'Bundle']\n",
    "\n",
    "temp_buat_bundle = null_telkom.groupby(['Order #', 'Bundle Name']).agg({'WH' : 'first', 'Outbound Status' : 'first', 'Outbound Qty' : 'max', 'Qty. Invoiced' : 'max'}).reset_index()\n",
    "temp_buat_bundle['Outbound Qty'] = temp_buat_bundle['Outbound Qty']/temp_buat_bundle['Qty. Invoiced']\n",
    "temp_buat_bundle = temp_buat_bundle.drop('Qty. Invoiced', axis = 1)\n",
    "\n",
    "null_telkom_bundle = null_telkom_bundle.merge(temp_buat_bundle.drop_duplicates(['Order #', 'Bundle Name']), how = 'left', left_on = ['Order #', 'Product Name'], right_on = ['Order #', 'Bundle Name']).set_index(null_telkom_bundle.index)\n",
    "null_telkom_bundle['Outbound Qty_y'] = null_telkom_bundle['Outbound Qty_y']*null_telkom_bundle['Qty. Invoiced']\n",
    "\n",
    "null_telkom['Outbound Status'][null_telkom_bundle.index] = null_telkom_bundle['Outbound Status_y']\n",
    "null_telkom['WH'][null_telkom_bundle.index] = null_telkom_bundle['WH_y']\n",
    "null_telkom['Outbound Qty'][null_telkom_bundle.index] = null_telkom_bundle['Outbound Qty_y'] \n",
    "\n",
    "nutrimart_wms['Outbound Status'][null_telkom.index] = null_telkom['Outbound Status']\n",
    "nutrimart_wms['WH'][null_telkom.index] = null_telkom['WH']\n",
    "nutrimart_wms['Outbound Qty'][null_telkom.index] = null_telkom['Outbound Qty'] \n",
    "\n",
    "# unavail = orders[(orders['channel'].isin(['Nutrimart', 'Nutrimart '])) & (orders['status'] == 'unavailable')]['invoice_number'].astype(str).str.replace('.0', '', regex = False).unique()\n",
    "# indeks = nutrimart_wms[(nutrimart_wms['Outbound Status'].isnull()) & (nutrimart_wms['Order #'].astype(str).isin(unavail))].index.to_list()\n",
    "# nutrimart_wms['Outbound Status'][indeks] = 'unavailable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "### run 13\n",
    "temp_telkom = nutrimart_merge.copy()\n",
    "\n",
    "indeks = temp_telkom[(temp_telkom['Real SKU'] == '7300281') & (temp_telkom['Bundle Name'].isnull())].index.to_list()\n",
    "temp_telkom['Brand'][indeks] = 'Bundle'\n",
    "\n",
    "temp_telkom['Order #'] = temp_telkom['Order #'].astype(str)\n",
    "wms_telkom['Order #'] = wms_telkom['Order #'].astype(str)\n",
    "\n",
    "temp_telkom['Real SKU'] = temp_telkom['Real SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_telkom['SKU WH'] = wms_telkom['SKU WH'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "temp_telkom = temp_telkom.merge(wms_telkom.drop_duplicates(['Order #', 'SKU WH']), how = 'left', left_on = ['Order #', 'Real SKU'], right_on = ['Order #', 'SKU WH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### to next sign #######################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Channel</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Bundle Name</th>\n",
       "      <th>Price List NFI</th>\n",
       "      <th>Qty. Invoiced</th>\n",
       "      <th>Total Net</th>\n",
       "      <th>Sub Brand</th>\n",
       "      <th>Real SKU</th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Parent Item</th>\n",
       "      <th>Parent SKU</th>\n",
       "      <th>Bundle Flag</th>\n",
       "      <th>Customer Email</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Customer Group</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>City</th>\n",
       "      <th>Kecamatan</th>\n",
       "      <th>Kelurahan</th>\n",
       "      <th>Address</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Shipping Name</th>\n",
       "      <th>Shipping Courier</th>\n",
       "      <th>Total</th>\n",
       "      <th>Coupon Code</th>\n",
       "      <th>Qty. Ordered</th>\n",
       "      <th>Qty. Shipped</th>\n",
       "      <th>Qty. Refunded</th>\n",
       "      <th>Item Price</th>\n",
       "      <th>Subtotal</th>\n",
       "      <th>Discounts</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Total incl. Tax</th>\n",
       "      <th>Invoiced</th>\n",
       "      <th>Tax Invoiced</th>\n",
       "      <th>Invoiced incl. Tax</th>\n",
       "      <th>Refunded</th>\n",
       "      <th>Refunded incl. Tax</th>\n",
       "      <th>Cart Name Rule</th>\n",
       "      <th>Payment Channel</th>\n",
       "      <th>Voucher Amount</th>\n",
       "      <th>Discount Poin Reward</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Discount Product</th>\n",
       "      <th>Produk 1</th>\n",
       "      <th>SKU Produk 1</th>\n",
       "      <th>PCS Produk 1</th>\n",
       "      <th>Price List NFI 1</th>\n",
       "      <th>Subtotal Produk 1</th>\n",
       "      <th>Harga Display 1</th>\n",
       "      <th>Harga Cost 1</th>\n",
       "      <th>Produk 2</th>\n",
       "      <th>SKU Produk 2</th>\n",
       "      <th>PCS Produk 2</th>\n",
       "      <th>Price List NFI 2</th>\n",
       "      <th>Subtotal Produk 2</th>\n",
       "      <th>Harga Display 2</th>\n",
       "      <th>Harga Cost 2</th>\n",
       "      <th>Produk 3</th>\n",
       "      <th>SKU Produk 3</th>\n",
       "      <th>...</th>\n",
       "      <th>Payment Status</th>\n",
       "      <th>Payment Type</th>\n",
       "      <th>Printed Date</th>\n",
       "      <th>Fulfilled Date</th>\n",
       "      <th>Delivered Date</th>\n",
       "      <th>Return ID</th>\n",
       "      <th>Return Reference No.</th>\n",
       "      <th>Return Date</th>\n",
       "      <th>Service Type</th>\n",
       "      <th>Bundle SKU Code</th>\n",
       "      <th>Location ID</th>\n",
       "      <th>Invoice ID</th>\n",
       "      <th>Invoice Reference Number</th>\n",
       "      <th>Invoice Status</th>\n",
       "      <th>Invoice Create Date</th>\n",
       "      <th>Fee Amount</th>\n",
       "      <th>Invoice Amount</th>\n",
       "      <th>Payment Received ID</th>\n",
       "      <th>Payment Received Ref. number</th>\n",
       "      <th>Category Baru</th>\n",
       "      <th>Exported Parent Item</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Price List NFI_x</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Real Region</th>\n",
       "      <th>True datetime1</th>\n",
       "      <th>Payment Date</th>\n",
       "      <th>Shipping Customer Name</th>\n",
       "      <th>Shipped Date</th>\n",
       "      <th>Note</th>\n",
       "      <th>Ready to Ship Date</th>\n",
       "      <th>Completed Date</th>\n",
       "      <th>Cancelled Reason</th>\n",
       "      <th>Item Note</th>\n",
       "      <th>Shipping Fee (Cashless)</th>\n",
       "      <th>Picklist ID</th>\n",
       "      <th>Package ID</th>\n",
       "      <th>Shipment ID</th>\n",
       "      <th>Bundle SKU</th>\n",
       "      <th>Alamat pengambilan</th>\n",
       "      <th>Alamat</th>\n",
       "      <th>Kota</th>\n",
       "      <th>Provinsi</th>\n",
       "      <th>Harga item pesanan</th>\n",
       "      <th>Total harga item pesanan</th>\n",
       "      <th>Diskon</th>\n",
       "      <th>Nama diskon</th>\n",
       "      <th>Kode diskon</th>\n",
       "      <th>Voucher seller</th>\n",
       "      <th>Nama voucher seller</th>\n",
       "      <th>Kode voucher seller</th>\n",
       "      <th>Nama voucher gratis ongkir</th>\n",
       "      <th>Kode voucher gratis ongkir</th>\n",
       "      <th>Catatan produk</th>\n",
       "      <th>Tanggal pengiriman</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Second</th>\n",
       "      <th>Tracking Id</th>\n",
       "      <th>Paid Total</th>\n",
       "      <th>Seller Voucher</th>\n",
       "      <th>Other Discounts</th>\n",
       "      <th>Shipping Fee</th>\n",
       "      <th>Customer E-mail</th>\n",
       "      <th>Order Completion Date</th>\n",
       "      <th>Pickup Timeslot</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Parent Order Number</th>\n",
       "      <th>Order Date Selcen</th>\n",
       "      <th>Status Seller Centre</th>\n",
       "      <th>Total Selcen</th>\n",
       "      <th>invoice_number</th>\n",
       "      <th>SKU WH</th>\n",
       "      <th>Outbound Status</th>\n",
       "      <th>WH</th>\n",
       "      <th>Outbound Qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18427</th>\n",
       "      <td>#1180</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2024-05-05 10:03:47</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>May</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Nutrimart - Reseller</td>\n",
       "      <td>2101500195P6</td>\n",
       "      <td>HiLo</td>\n",
       "      <td>HiLo Gold Plain 1000 gr -6 DUS</td>\n",
       "      <td>HiLo Gold Plain 1000 gr -6 DUS</td>\n",
       "      <td>146520.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1758240.0</td>\n",
       "      <td>HILO GOLD</td>\n",
       "      <td>2101500195</td>\n",
       "      <td>HiLo Gold Plain 1000 gr</td>\n",
       "      <td>HiLo Gold Plain 1000 gr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>087886811687</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Dki Jakarta</td>\n",
       "      <td>Kota Jakarta Pusat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jl Nawa Gg Nawa 2 No 15c Jakarta Pusat, Kemayo...</td>\n",
       "      <td>10650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reseller Free Delivery</td>\n",
       "      <td>1499452.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Payments via Midtrans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HILO GOLD</td>\n",
       "      <td>HILO GOLD PLAIN 6DX1000G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2101500195P6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1499452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>grieshella26@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Out of Stock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18428</th>\n",
       "      <td>#1180</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2024-05-05 10:03:47</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>May</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Nutrimart - Reseller</td>\n",
       "      <td>2101486195P6</td>\n",
       "      <td>HiLo</td>\n",
       "      <td>HiLo School Vanilla 1000g -6 DUS</td>\n",
       "      <td>HiLo School Vanilla 1000g -6 DUS</td>\n",
       "      <td>149850.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1798200.0</td>\n",
       "      <td>HILO SCHOOL</td>\n",
       "      <td>2101486195</td>\n",
       "      <td>HiLo School Vanilla 1000g</td>\n",
       "      <td>HiLo School Vanilla 1000g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>087886811687</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Dki Jakarta</td>\n",
       "      <td>Kota Jakarta Pusat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jl Nawa Gg Nawa 2 No 15c Jakarta Pusat, Kemayo...</td>\n",
       "      <td>10650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reseller Free Delivery</td>\n",
       "      <td>1533564.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Payments via Midtrans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HILO SCHOOL</td>\n",
       "      <td>HILO SCHOOL VANILLA 6DX1000G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jabodetabek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2101486195P6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1533564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>grieshella26@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Out of Stock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Order # Sales Order ID AWB  Paid Date Order Status           Order date  \\\n",
       "18427   #1180            NaN            NaN      Partial  2024-05-05 10:03:47   \n",
       "18428   #1180            NaN            NaN      Partial  2024-05-05 10:03:47   \n",
       "\n",
       "       Week  Date Month  Quarter    Year               Channel           SKU  \\\n",
       "18427  18.0   5.0   May      2.0  2024.0  Nutrimart - Reseller  2101500195P6   \n",
       "18428  18.0   5.0   May      2.0  2024.0  Nutrimart - Reseller  2101486195P6   \n",
       "\n",
       "      Brand                      Product Name  \\\n",
       "18427  HiLo    HiLo Gold Plain 1000 gr -6 DUS   \n",
       "18428  HiLo  HiLo School Vanilla 1000g -6 DUS   \n",
       "\n",
       "                            Bundle Name  Price List NFI  Qty. Invoiced  \\\n",
       "18427    HiLo Gold Plain 1000 gr -6 DUS        146520.0           12.0   \n",
       "18428  HiLo School Vanilla 1000g -6 DUS        149850.0           12.0   \n",
       "\n",
       "       Total Net    Sub Brand    Real SKU           Real Nama Produk  \\\n",
       "18427  1758240.0    HILO GOLD  2101500195    HiLo Gold Plain 1000 gr   \n",
       "18428  1798200.0  HILO SCHOOL  2101486195  HiLo School Vanilla 1000g   \n",
       "\n",
       "                     Parent Item  Parent SKU Bundle Flag Customer Email  \\\n",
       "18427    HiLo Gold Plain 1000 gr         NaN         Kit            NaN   \n",
       "18428  HiLo School Vanilla 1000g         NaN         Kit            NaN   \n",
       "\n",
       "      Customer Name Customer Group         Phone    Country       Region  \\\n",
       "18427        Shella            NaN  087886811687  Indonesia  Dki Jakarta   \n",
       "18428        Shella            NaN  087886811687  Indonesia  Dki Jakarta   \n",
       "\n",
       "                     City Kecamatan Kelurahan  \\\n",
       "18427  Kota Jakarta Pusat       NaN       NaN   \n",
       "18428  Kota Jakarta Pusat       NaN       NaN   \n",
       "\n",
       "                                                 Address Zip Code  \\\n",
       "18427  Jl Nawa Gg Nawa 2 No 15c Jakarta Pusat, Kemayo...    10650   \n",
       "18428  Jl Nawa Gg Nawa 2 No 15c Jakarta Pusat, Kemayo...    10650   \n",
       "\n",
       "      Shipping Name        Shipping Courier      Total Coupon Code  \\\n",
       "18427           NaN  Reseller Free Delivery  1499452.0         NaN   \n",
       "18428           NaN  Reseller Free Delivery  1533564.0         NaN   \n",
       "\n",
       "       Qty. Ordered  Qty. Shipped  Qty. Refunded  Item Price  Subtotal  \\\n",
       "18427           NaN           NaN            NaN         NaN       NaN   \n",
       "18428           NaN           NaN            NaN         NaN       NaN   \n",
       "\n",
       "       Discounts  Tax  Total incl. Tax  Invoiced  Tax Invoiced  \\\n",
       "18427        NaN  0.0              NaN       NaN           NaN   \n",
       "18428        NaN  0.0              NaN       NaN           NaN   \n",
       "\n",
       "       Invoiced incl. Tax  Refunded  Refunded incl. Tax Cart Name Rule  \\\n",
       "18427                 NaN       NaN                 NaN            NaN   \n",
       "18428                 NaN       NaN                 NaN            NaN   \n",
       "\n",
       "             Payment Channel  Voucher Amount  Discount Poin Reward Ship Date  \\\n",
       "18427  Payments via Midtrans             NaN                   NaN       NaN   \n",
       "18428  Payments via Midtrans             NaN                   NaN       NaN   \n",
       "\n",
       "       Discount Product Produk 1 SKU Produk 1  PCS Produk 1  Price List NFI 1  \\\n",
       "18427               NaN      NaN          NaN           NaN               NaN   \n",
       "18428               NaN      NaN          NaN           NaN               NaN   \n",
       "\n",
       "       Subtotal Produk 1  Harga Display 1  Harga Cost 1 Produk 2 SKU Produk 2  \\\n",
       "18427                NaN              NaN           NaN      NaN          NaN   \n",
       "18428                NaN              NaN           NaN      NaN          NaN   \n",
       "\n",
       "       PCS Produk 2  Price List NFI 2  Subtotal Produk 2  Harga Display 2  \\\n",
       "18427           NaN               NaN                NaN              NaN   \n",
       "18428           NaN               NaN                NaN              NaN   \n",
       "\n",
       "       Harga Cost 2 Produk 3 SKU Produk 3  ...  Payment Status  Payment Type  \\\n",
       "18427           NaN      NaN          NaN  ...             NaN           NaN   \n",
       "18428           NaN      NaN          NaN  ...             NaN           NaN   \n",
       "\n",
       "       Printed Date  Fulfilled Date  Delivered Date Return ID  \\\n",
       "18427           NaN             NaN             NaN       NaN   \n",
       "18428           NaN             NaN             NaN       NaN   \n",
       "\n",
       "      Return Reference No.  Return Date  Service Type  Bundle SKU Code  \\\n",
       "18427                  NaN          NaN           NaN              NaN   \n",
       "18428                  NaN          NaN           NaN              NaN   \n",
       "\n",
       "       Location ID  Invoice ID Invoice Reference Number Invoice Status  \\\n",
       "18427          NaN         NaN                      NaN            NaN   \n",
       "18428          NaN         NaN                      NaN            NaN   \n",
       "\n",
       "       Invoice Create Date  Fee Amount  Invoice Amount  Payment Received ID  \\\n",
       "18427                  NaN         NaN             NaN                  NaN   \n",
       "18428                  NaN         NaN             NaN                  NaN   \n",
       "\n",
       "       Payment Received Ref. number Category Baru  \\\n",
       "18427                           NaN     HILO GOLD   \n",
       "18428                           NaN   HILO SCHOOL   \n",
       "\n",
       "               Exported Parent Item  Unnamed: 0  Price List NFI_x  \\\n",
       "18427      HILO GOLD PLAIN 6DX1000G         NaN               NaN   \n",
       "18428  HILO SCHOOL VANILLA 6DX1000G         NaN               NaN   \n",
       "\n",
       "       Customer Type  Real Region  True datetime1 Payment Date  \\\n",
       "18427            NaN  Jabodetabek             NaN          NaN   \n",
       "18428            NaN  Jabodetabek             NaN          NaN   \n",
       "\n",
       "      Shipping Customer Name  Shipped Date  Note  Ready to Ship Date  \\\n",
       "18427                    NaN           NaN   NaN                 NaN   \n",
       "18428                    NaN           NaN   NaN                 NaN   \n",
       "\n",
       "       Completed Date  Cancelled Reason Item Note Shipping Fee (Cashless)  \\\n",
       "18427             NaN               NaN       NaN                     NaN   \n",
       "18428             NaN               NaN       NaN                     NaN   \n",
       "\n",
       "       Picklist ID  Package ID  Shipment ID    Bundle SKU  Alamat pengambilan  \\\n",
       "18427          NaN         NaN          NaN  2101500195P6                 NaN   \n",
       "18428          NaN         NaN          NaN  2101486195P6                 NaN   \n",
       "\n",
       "       Alamat  Kota  Provinsi  Harga item pesanan  Total harga item pesanan  \\\n",
       "18427     NaN   NaN       NaN                 NaN                       NaN   \n",
       "18428     NaN   NaN       NaN                 NaN                       NaN   \n",
       "\n",
       "       Diskon  Nama diskon Kode diskon  Voucher seller Nama voucher seller  \\\n",
       "18427     NaN          NaN         NaN             NaN                 NaN   \n",
       "18428     NaN          NaN         NaN             NaN                 NaN   \n",
       "\n",
       "       Kode voucher seller  Nama voucher gratis ongkir  \\\n",
       "18427                  NaN                         NaN   \n",
       "18428                  NaN                         NaN   \n",
       "\n",
       "       Kode voucher gratis ongkir  Catatan produk  Tanggal pengiriman  Minute  \\\n",
       "18427                         NaN             NaN                 NaN     NaN   \n",
       "18428                         NaN             NaN                 NaN     NaN   \n",
       "\n",
       "       Second  Tracking Id  Paid Total Seller Voucher Other Discounts  \\\n",
       "18427     NaN          NaN   1499452.0            0.0             0.0   \n",
       "18428     NaN          NaN   1533564.0            0.0             0.0   \n",
       "\n",
       "      Shipping Fee         Customer E-mail  Order Completion Date  \\\n",
       "18427          0.0  grieshella26@gmail.com                    NaN   \n",
       "18428          0.0  grieshella26@gmail.com                    NaN   \n",
       "\n",
       "       Pickup Timeslot        Reason  Parent Order Number Order Date Selcen  \\\n",
       "18427              NaN  Out of Stock                  NaN               NaN   \n",
       "18428              NaN  Out of Stock                  NaN               NaN   \n",
       "\n",
       "       Status Seller Centre  Total Selcen  invoice_number  SKU WH  \\\n",
       "18427                   NaN           0.0             NaN     NaN   \n",
       "18428                   NaN           0.0             NaN     NaN   \n",
       "\n",
       "       Outbound Status   WH  Outbound Qty  \n",
       "18427              NaN  NaN           NaN  \n",
       "18428              NaN  NaN           NaN  \n",
       "\n",
       "[2 rows x 247 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_telkom[temp_telkom['Order #']=='#1180']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wms_telkom_cp = pd.read_csv(r'Backup WMS Telkom.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrimart_wms.to_csv(r'D:\\Backup\\Backup 26 Mei\\Settlement Project Backup/Nutrimart Qty.csv', index = False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pypyodbc\n",
    "\n",
    "conn = pypyodbc.connect('Driver={SQL Server};'\n",
    "                'Server=NFI-DB-01;'\n",
    "                'Database=gudang;'\n",
    "                'UID=andra.miftah;'\n",
    "                'PWD=24nutrifoodindonesia21;'\n",
    "                )\n",
    "\n",
    "cursor = conn.cursor()\n",
    "wms_backup = pd.read_sql(r\"\"\"SELECT t1.id, t1.order_id,t1.status, t1.quantity, t1.product_id, t2.id,  t2.order_number, t2.invoice_number, t2.channel, t2.order_date, t3.id, t3.sku, t3.name\n",
    "  FROM [gudang].[dbo].[outbound_items] as t1\n",
    "  left join orders as t2\n",
    "  on t1.order_id = t2.id\n",
    "  left join products as t3\n",
    "  on t1.product_id = t3.id\"\"\", conn)\n",
    "                         \n",
    "outbound_items = pd.read_csv(r'Backup Gudang 4 Sept 2021 Gudang Baru/outbound_items.csv', sep = ';')\n",
    "orders = pd.read_csv(r'Backup Gudang 4 Sept 2021 Gudang Baru/orders.csv', sep = ';')\n",
    "products = pd.read_csv(r'Backup Gudang 4 Sept 2021 Gudang Baru/products.csv', sep = ';')\n",
    "\n",
    "wms_backup2 = outbound_items[['id', 'order_id','status', 'quantity', 'product_id']].merge(\n",
    "    orders[['id',  'order_number', 'invoice_number', 'channel', 'order_date']], how = 'left', left_on = 'order_id', right_on = 'id'\n",
    ").merge(\n",
    "    products[['id', 'sku', 'name']], how = 'left', left_on = 'product_id', right_on = 'id'\n",
    ")\n",
    "wms_backup = wms_backup[wms_backup['channel'].isin(['Nutrimart', 'Nutrimart '])]\n",
    "wms_backup2 = wms_backup2[wms_backup2['channel'].isin(['Nutrimart', 'Nutrimart '])]\n",
    "\n",
    "wms_backup = wms_backup[['order_number','invoice_number', 'sku', 'name', 'status', 'quantity']].drop_duplicates()\n",
    "wms_backup2 = wms_backup2[['order_number','invoice_number', 'sku', 'name', 'status', 'quantity']].drop_duplicates()\n",
    "\n",
    "wms_backup['invoice_number'] = wms_backup['invoice_number'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_backup['order_number'] = wms_backup['order_number'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_backup['sku'] = wms_backup['sku'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "wms_backup2['invoice_number'] = wms_backup2['invoice_number'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_backup2['order_number'] = wms_backup2['order_number'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_backup2['sku'] = wms_backup2['sku'].astype(str).str.replace('.0', '', regex = False)\n",
    "\n",
    "wms_backup = wms_backup.append(wms_backup2, ignore_index = True, sort = False)\n",
    "wms_backup_cp = wms_backup.copy()\n",
    "\n",
    "min1 = wms_backup[wms_backup['order_number'].astype(str).str.contains('-1')]\n",
    "min1['order_number'] = min1['order_number'].astype(str).str.replace('-1', '', regex = False)\n",
    "\n",
    "temp_telkom = wms_backup.merge(min1, how = 'left', on = ['order_number', 'sku'])\n",
    "indeks = temp_telkom[temp_telkom['invoice_number_y'].notnull()].index.to_list()\n",
    "wms_backup = wms_backup.drop(indeks, axis = 0)\n",
    "\n",
    "wms_backup['order_number'] = wms_backup['order_number'].astype(str).str.replace('-1', '', regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wms_backup['WH'] = 'Telkom'\n",
    "wms_backup = wms_backup.rename(columns = {'order_number' : 'Order #', 'status':'Outbound Status', 'sku' : 'SKU WH', 'quantity' : 'Outbound Qty'})\n",
    "\n",
    "\n",
    "null_wms = nutrimart_wms[(nutrimart_wms['WH'].isnull())\n",
    "            & (nutrimart_wms['Brand'] != 'Bundle') &\n",
    "            (nutrimart_wms['Order #'].isin(wms_backup['Order #']))]\n",
    "\n",
    "\n",
    "null_wms['Order #'] = null_wms['Order #'].astype(str)\n",
    "wms_backup['Order #'] = wms_backup['Order #'].astype(str)\n",
    "\n",
    "wms_backup['SKU WH'] = wms_backup['SKU WH'].astype(str)\n",
    "\n",
    "null_wms = null_wms.merge(wms_backup.drop_duplicates(['Order #', 'name']), how = 'left', left_on = ['Order #', 'Product Name'], right_on = ['Order #', 'name'])\n",
    "null_wms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wms_telkom['WH'] = 'Telkom'\n",
    "wms_telkom = wms_telkom.rename(columns = {'invoice_number' : 'Order #', 'status':'Outbound Status', 'sku' : 'SKU WH', 'quantity' : 'Outbound Qty'})\n",
    "\n",
    "temp_telkom = nutrimart_merge.copy()\n",
    "\n",
    "temp_telkom['Order #'] = temp_telkom['Order #'].astype(str)\n",
    "wms_telkom['Order #'] = wms_telkom['Order #'].astype(str)\n",
    "\n",
    "temp_telkom['Real SKU'] = temp_telkom['Real SKU'].astype(str).str.replace('.0', '', regex = False)\n",
    "wms_telkom['SKU WH'] = wms_telkom['SKU WH'].astype(str)\n",
    "\n",
    "temp_telkom = temp_telkom.merge(wms_telkom.drop_duplicates(['Order #', 'SKU WH']), how = 'left', left_on = ['Order #', 'Real SKU'], right_on = ['Order #', 'SKU WH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================run ini=========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_317315.csv\n",
      "export_317316.csv\n",
      "export_317317.csv\n",
      "export_317318.csv\n",
      "export_317319.csv\n",
      "export_317320.csv\n",
      "export_317321.csv\n",
      "export_317322.csv\n",
      "export_317323.csv\n",
      "export_317324.csv\n",
      "Nutrimart Seller Centre 1-28 Feb 2022.csv\n",
      "Nutrimart Seller Centre 1-30 Nov.csv\n",
      "Nutrimart Seller Centre 1-31 Des.csv\n",
      "Nutrimart Seller Centre 1-31 Jan.csv\n",
      "Nutrimart Seller Centre 1-31 Mar 2022.csv\n",
      "Nutrimart Seller Centre 1-31 Oct.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 14\n",
    "null_shipping = nutrimart_wms[nutrimart_wms['Shipping'].isnull()].copy()\n",
    "\n",
    "ship = pd.DataFrame()\n",
    "\n",
    "for i in os.listdir('Settlement Project/Nutrimart/Shipping Nutrimart/'):\n",
    "    print(i)\n",
    "    temp = pd.read_csv('Settlement Project/Nutrimart/Shipping Nutrimart/' + str(i), index_col = False)\n",
    "    ship = ship.append(temp, ignore_index = True, sort = False)\n",
    "    \n",
    "for i in range(ship.shape[1]):\n",
    "    ship = ship.rename(columns={ ship.columns[i] : ship.columns[i].replace(\"    \",\" \")})\n",
    "        \n",
    "ship['Order #'] = ship['Sales Order Id'].astype(str)\n",
    "ship['SKU'] = ship['Sku'].astype(str).str.split('-', expand = True)[0]\n",
    "ship['Selling Price'] = ship['Price']\n",
    "ship['Product Name'] = ship['Item Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "ship['Bundle Name'] = ship['Bundle Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "\n",
    "ship_real = ship[ship['Bundle Name'] == 'nan']\n",
    "ship_bundle = ship[ship['Bundle Name'] != 'nan']\n",
    "\n",
    "ship_real['Shipping Cost'] =  ship_real['Shipping Cost'] * ship_real['Price']/ship_real.groupby('Sales Order Id')['Price'].transform('sum')\n",
    "\n",
    "ship_bundle = ship_bundle.drop('Shipping Cost', axis = 1)\n",
    "ship_bundle = ship_bundle.merge(ship_real[['Sales Order Id', 'Product Name', 'Shipping Cost']].drop_duplicates(['Sales Order Id', 'Product Name']), how = 'left', left_on = ['Sales Order Id', 'Bundle Name'], right_on = ['Sales Order Id', 'Product Name'])\n",
    "ship_bundle = ship_bundle.drop('Product Name_y', axis = 1).rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "ship_bundle['Shipping Cost'] =  ship_bundle['Shipping Cost'] * ship_bundle['Price']/ship_bundle.groupby(['Sales Order Id', 'Bundle Name'])['Price'].transform('sum')\n",
    "\n",
    "ship = ship_real.append(ship_bundle, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2008\n",
      "2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n",
      "2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 15\n",
    "null_shipping['Order #'] = null_shipping['Order #'].astype(str)\n",
    "null_shipping['Product Name'] = null_shipping['Product Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "null_shipping['Bundle Name'] = null_shipping['Bundle Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "null_shipping['SKU'] = null_shipping['SKU'].astype(str)\n",
    "\n",
    "print(len(null_shipping))\n",
    "null_shipping = null_shipping.merge(ship.drop_duplicates()[['Order #', 'Product Name', 'Bundle Name', 'SKU', 'Selling Price', 'Shipping Cost']].drop_duplicates(), how = 'left', on = ['Order #', 'Product Name', 'Bundle Name', 'SKU', 'Selling Price']).set_index(null_shipping.index)\n",
    "print(len(null_shipping))\n",
    "nutrimart_wms['Shipping'][null_shipping.index] = null_shipping['Shipping Cost_y']\n",
    "\n",
    "null_shipping = nutrimart_wms[nutrimart_wms['Shipping'].isnull()].copy()\n",
    "null_shipping['Order #'] = null_shipping['Order #'].astype(str)\n",
    "null_shipping['Product Name'] = null_shipping['Product Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "null_shipping['Bundle Name'] = null_shipping['Bundle Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "null_shipping['SKU'] = null_shipping['SKU'].astype(str)\n",
    "print(len(null_shipping))\n",
    "null_shipping = null_shipping.merge(ship.drop_duplicates()[['Order #', 'Product Name', 'Bundle Name', 'SKU', 'Shipping Cost']].drop_duplicates(), how = 'left', on = ['Order #', 'Product Name', 'Bundle Name', 'SKU']).set_index(null_shipping.index)\n",
    "print(len(null_shipping))\n",
    "nutrimart_wms['Shipping'][null_shipping.index] = null_shipping['Shipping Cost_y']\n",
    "\n",
    "null_shipping = nutrimart_wms[nutrimart_wms['Shipping'].isnull()].copy()\n",
    "null_shipping['Order #'] = null_shipping['Order #'].astype(str)\n",
    "null_shipping['Product Name'] = null_shipping['Product Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "null_shipping['Bundle Name'] = null_shipping['Bundle Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "null_shipping['SKU'] = null_shipping['SKU'].astype(str)\n",
    "print(len(null_shipping))\n",
    "null_shipping = null_shipping.merge(ship.drop_duplicates()[['Order #', 'Product Name', 'Bundle Name','Shipping Cost']].drop_duplicates(), how = 'left', on = ['Order #', 'Product Name', 'Bundle Name']).set_index(null_shipping.index)\n",
    "print(len(null_shipping))\n",
    "nutrimart_wms['Shipping'][null_shipping.index] = null_shipping['Shipping Cost_y']\n",
    "\n",
    "null_shipping = nutrimart_wms[nutrimart_wms['Shipping'].isnull()].copy()\n",
    "null_shipping['Order #'] = null_shipping['Order #'].astype(str)\n",
    "null_shipping['Product Name'] = null_shipping['Product Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "null_shipping['Bundle Name'] = null_shipping['Bundle Name'].astype(str).str.replace('  ', ' ').str.replace('\\xa0', ' ', regex = False).str.strip()\n",
    "null_shipping['SKU'] = null_shipping['SKU'].astype(str)\n",
    "print(len(null_shipping))\n",
    "null_shipping = null_shipping.merge(ship.drop_duplicates()[['Order #', 'Product Name', 'Bundle Name','Shipping Cost']].drop_duplicates(['Order #', 'Product Name']), how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name']).set_index(null_shipping.index)\n",
    "print(len(null_shipping))\n",
    "nutrimart_wms['Shipping'][null_shipping.index] = null_shipping['Shipping Cost_y']\n",
    "\n",
    "indeks = nutrimart_wms[nutrimart_wms['Bundle Name'] == 'nan'].index.to_list()\n",
    "nutrimart_wms['Bundle Name'][indeks] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name_x</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Order #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Product Name_x, SKU, Order #]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking\n",
    "ship_null = ship[ship['Shipping Cost'].isnull()]['Order #'].unique()\n",
    "\n",
    "null_shipping[(null_shipping['Order #'].isin(ship['Order #'])) & \n",
    "              (null_shipping['Shipping Cost_y'].isnull()) &\n",
    "              (~null_shipping['Order #'].isin(ship_null))\n",
    "             ].groupby(['Product Name_x', 'SKU'])['Order #'].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cek Voucher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for display\n",
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 16\n",
    "# Cek Voucher Ongkir\n",
    "\n",
    "### tambahan timo april 23\n",
    "nutrimart_wms['Coupon Code']=nutrimart_wms['Coupon Code'].str.upper()\n",
    "### tambahan timo april 23\n",
    "\n",
    "\n",
    "nutrimart_wms['Voucher Ongkir'] = np.nan\n",
    "\n",
    "null_ongkir =  nutrimart_wms.groupby('Order #')['Shipping'].sum().reset_index()\n",
    "null_ongkir = null_ongkir[null_ongkir['Shipping'] == 0]['Order #'].unique()\n",
    "\n",
    "indeks = nutrimart_wms[nutrimart_wms['Order #'].isin(null_ongkir)].index.to_list()\n",
    "print(len(indeks))\n",
    "nutrimart_wms['Voucher Ongkir'][indeks] = 'Ada'\n",
    "\n",
    "coupon_ongkir = pd.read_excel(r'Settlement Project\\Nutrimart/Coupon Code Organic Real.xlsx')\n",
    "coupon_ongkir = coupon_ongkir[coupon_ongkir['description'].astype(str).str.contains('ongkir', case = False)]['code'].unique()\n",
    "\n",
    "indeks = nutrimart_wms[nutrimart_wms['Coupon Code'].isin(coupon_ongkir)].index.to_list()\n",
    "print(len(indeks))\n",
    "nutrimart_wms['Voucher Ongkir'][indeks] = 'Ada'\n",
    "\n",
    "# Voucher Product\n",
    "\n",
    "nutrimart_wms['Voucher Product'] = nutrimart_wms['Voucher Amount']\n",
    "\n",
    "nutrimart_real = nutrimart_wms[nutrimart_wms['Bundle Name'].isnull()]\n",
    "nutrimart_bundle = nutrimart_wms[nutrimart_wms['Bundle Name'].notnull()]\n",
    "nutrimart_bundle = nutrimart_bundle.drop('Voucher Product', axis = 1)\n",
    "\n",
    "bundle_merge = nutrimart_bundle.merge(nutrimart_real[['Order #', 'Product Name','Voucher Product']].drop_duplicates(['Order #', 'Product Name']), how = 'left', \n",
    "                                 left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "bundle_merge = bundle_merge.rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "bundle_merge = bundle_merge.drop('Product Name_y', axis = 1)\n",
    "\n",
    "bundle_merge['Voucher Product'] = bundle_merge['Voucher Product'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_wms = nutrimart_real.append(bundle_merge, ignore_index = True, sort = False)\n",
    "\n",
    "coupon_product = pd.read_excel(r'Settlement Project\\Nutrimart/Master kode Voucher NutriMart-fix.xlsx')\n",
    "coupon_product = coupon_product[['coupon', 'Pemilik Budget', 'Cluster']]\n",
    "coupon_product['Coupon Code'] = coupon_product['coupon'].astype(str)\n",
    "\n",
    "nutrimart_wms['Coupon Code'] = nutrimart_wms['Coupon Code'].astype(str)\n",
    "indeks = nutrimart_wms[nutrimart_wms['Coupon Code'] == 'nan'].index.to_list()\n",
    "nutrimart_wms['Coupon Code'][indeks] = np.nan\n",
    "nutrimart_vou = nutrimart_wms.merge(coupon_product.drop_duplicates('Coupon Code'), how = 'left', on = 'Coupon Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 17\n",
    "temp = nutrimart_vou[(nutrimart_vou['Year'].isin([2022,2023,2024])) & (nutrimart_vou['Pemilik Budget'].isnull()) & (nutrimart_vou['Coupon Code'].notnull())]\n",
    "\n",
    "area = pd.read_excel(r\"Settlement Project\\Nutrimart\\voucher.xlsx\", sheet_name = 'Area')\n",
    "cluster = pd.read_excel(r\"Settlement Project\\Nutrimart\\voucher.xlsx\", sheet_name = 'Cluster')\n",
    "\n",
    "temp_coupon = temp[['Coupon Code']].drop_duplicates()\n",
    "\n",
    "temp_coupon['Coupon Code'] = temp_coupon['Coupon Code'].astype(str).str.upper()\n",
    "temp_coupon['Dept'] = np.nan\n",
    "temp_coupon['Cluster Code'] = np.nan\n",
    "\n",
    "temp_coupon['Original Coupon Code'] = temp_coupon['Coupon Code'].copy()\n",
    "\n",
    "for i in area['Kode Area']:\n",
    "    indeks = temp_coupon[temp_coupon['Coupon Code'].astype(str).str.upper().str.contains('^' + str(i), regex = True)].index.to_list()\n",
    "    if len(indeks) > 0 :\n",
    "        temp_coupon['Dept'][indeks] = 'Homdel'\n",
    "        temp_coupon['Coupon Code'][indeks] = temp_coupon['Coupon Code'][indeks].astype(str).str.upper().str.replace('^' + str(i), '', regex = True)\n",
    "        temp_coupon['Cluster Code'][indeks] = temp_coupon['Coupon Code'][indeks].astype(str).str[0]\n",
    "        indeks_2 = temp_coupon[~(temp_coupon['Cluster Code'].astype(str).str.isnumeric()) & (temp_coupon.index.isin(indeks))].index.to_list()\n",
    "        temp_coupon['Cluster Code'][indeks_2] = temp_coupon['Coupon Code'][indeks_2].astype(str).str[:3]\n",
    "        \n",
    "temp_coupon_null = temp_coupon[temp_coupon['Dept'].isnull()].copy()\n",
    "temp_coupon_null['Dept'] = temp_coupon_null['Coupon Code'].astype(str).str[:3]\n",
    "temp_coupon_null['Cluster Code'] = temp_coupon_null['Coupon Code'].astype(str).str[3:4]\n",
    "\n",
    "indeks_3 = temp_coupon_null[~(temp_coupon_null['Cluster Code'].astype(str).str.isnumeric())].index.to_list()\n",
    "temp_coupon_null['Cluster Code'][indeks_3] = temp_coupon_null['Coupon Code'][indeks_3].astype(str).str[3:6]\n",
    "\n",
    "temp_coupon['Dept'][temp_coupon_null.index] = temp_coupon_null['Dept']\n",
    "temp_coupon['Cluster Code'][temp_coupon_null.index] = temp_coupon_null['Cluster Code']\n",
    "\n",
    "cluster['Cluster Code'] = cluster['Cluster Code'].astype(str)\n",
    "temp_coupon['Cluster Code'] = temp_coupon['Cluster Code'].astype(str)\n",
    "\n",
    "#### 3huruf->pemilik budget\n",
    "\n",
    "temp_coupon = temp_coupon.merge(cluster, how = 'left', on = 'Cluster Code')\n",
    "\n",
    "temp = temp.drop(['Pemilik Budget', 'Cluster'], axis = 1)\n",
    "temp_coupon['Pemilik Budget'] = temp_coupon['Cluster']\n",
    "temp_coupon['Coupon Code'] = temp_coupon['Original Coupon Code']\n",
    "\n",
    "### tambahan timo Des22 jan 23\n",
    "deptlist=pd.read_excel(r\"Settlement Project\\Order Online\\Settement transfer, Kode Voucher\\deptlist_nfi.xlsx\")\n",
    "temp_coupon.loc[temp_coupon['Dept'].isin(deptlist['deptlist'].unique()),'Pemilik Budget']=temp_coupon['Dept']\n",
    "temp_coupon.loc[~temp_coupon['Dept'].isin(deptlist['deptlist'].unique()),'Pemilik Budget']=\"ECOM\"\n",
    "\n",
    "temp = temp.merge(temp_coupon[['Coupon Code', 'Pemilik Budget', 'Cluster']].drop_duplicates('Coupon Code'), how = 'left', on = 'Coupon Code').set_index(temp.index)\n",
    "\n",
    "nutrimart_vou['Pemilik Budget'][temp.index] = temp['Pemilik Budget']\n",
    "nutrimart_vou['Cluster'][temp.index] = temp['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order #</th>\n",
       "      <th>Sales Order ID</th>\n",
       "      <th>AWB</th>\n",
       "      <th>Paid Date</th>\n",
       "      <th>Order Status</th>\n",
       "      <th>Order date</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>invoice_number</th>\n",
       "      <th>SKU WH</th>\n",
       "      <th>Outbound Status</th>\n",
       "      <th>WH</th>\n",
       "      <th>Outbound Qty</th>\n",
       "      <th>Voucher Ongkir</th>\n",
       "      <th>Voucher Product</th>\n",
       "      <th>coupon</th>\n",
       "      <th>Pemilik Budget</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Order #, Sales Order ID, AWB, Paid Date, Order Status, Order date, Week, Date, Month, Quarter, Year, Channel, SKU, Brand, Product Name, Bundle Name, Price List NFI, Qty. Invoiced, Total Net, Sub Brand, Real SKU, Real Nama Produk, Parent Item, Parent SKU, Bundle Flag, Customer Email, Customer Name, Customer Group, Phone, Country, Region, City, Kecamatan, Kelurahan, Address, Zip Code, Shipping Name, Shipping Courier, Total, Coupon Code, Qty. Ordered, Qty. Shipped, Qty. Refunded, Item Price, Subtotal, Discounts, Tax, Total incl. Tax, Invoiced, Tax Invoiced, Invoiced incl. Tax, Refunded, Refunded incl. Tax, Cart Name Rule, Payment Channel, Voucher Amount, Discount Poin Reward, Ship Date, Discount Product, Produk 1, SKU Produk 1, PCS Produk 1, Price List NFI 1, Subtotal Produk 1, Harga Display 1, Harga Cost 1, Produk 2, SKU Produk 2, PCS Produk 2, Price List NFI 2, Subtotal Produk 2, Harga Display 2, Harga Cost 2, Produk 3, SKU Produk 3, PCS Produk 3, Price List NFI 3, Subtotal Produk 3, Harga Display 3, Harga Cost 3, Produk 4, SKU Produk 4, PCS Produk 4, Price List NFI 4, Subtotal Produk 4, Harga Display 4, Harga Cost 4, Produk 5, SKU Produk 5, PCS Produk 5, Price List NFI 5, Subtotal Produk 5, Harga Display 5, Harga Cost 5, Produk 6, SKU Produk 6, PCS Produk 6, Price List NFI 6, Subtotal Produk 6, Harga Display 6, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 260 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrimart_vou[(nutrimart_vou['Coupon Code'].notnull())&\n",
    "              (nutrimart_vou['Pemilik Budget'].isnull())]#['Coupon Code'].unique()\n",
    "# temp_coupon\n",
    "# temp #7968\n",
    "# nutrimart_vou\n",
    "# temp.iloc[7768]#1000118434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export_sales_detailed_report_317285.csv\n",
      "export_sales_detailed_report_317286.csv\n",
      "export_sales_detailed_report_317287.csv\n",
      "export_sales_detailed_report_317288.csv\n",
      "export_sales_detailed_report_317289.csv\n",
      "export_sales_detailed_report_317290.csv\n",
      "export_sales_detailed_report_317291.csv\n",
      "export_sales_detailed_report_317292.csv\n",
      "export_sales_detailed_report_317293.csv\n",
      "export_sales_detailed_report_317294.csv\n",
      "Nutrimart Seller Centre Details 1-28 Feb 2022.csv\n",
      "Nutrimart Seller Centre Details 1-30 Nov.csv\n",
      "Nutrimart Seller Centre Details 1-31 Des.csv\n",
      "Nutrimart Seller Centre Details 1-31 Jan 2022.csv\n",
      "Nutrimart Seller Centre Details 1-31 Mar 2022.csv\n",
      "Nutrimart Seller Centre Details 1-31 Oct.csv\n",
      "3\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### run 18\n",
    "details = pd.DataFrame()\n",
    "null_payment = nutrimart_vou[nutrimart_vou['Payment Channel'].isnull()]\n",
    "\n",
    "for i in os.listdir('Settlement Project/Nutrimart/Detail Salah/'):\n",
    "    print(i)\n",
    "    temp = pd.read_csv('Settlement Project/Nutrimart/Detail Salah/' + str(i), index_col = False)\n",
    "    details = details.append(temp, ignore_index = True, sort = False)\n",
    "        \n",
    "details['Order #'] = details['Order #'].astype(str)\n",
    "null_payment['Order #'] = null_payment['Order #'].astype(str)\n",
    "\n",
    "print(len(null_payment))\n",
    "null_payment = null_payment.merge(details[['Order #', 'Payment Channel']].drop_duplicates('Order #'), how = 'left', on = ['Order #']).set_index(null_payment.index)\n",
    "print(len(null_payment))\n",
    "nutrimart_vou['Payment Channel'][null_payment.index] = null_payment['Payment Channel_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorder Refund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 19\n",
    "refund1 = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'Reorder Refund')\n",
    "refund2 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2022 (New Format).xlsx', sheet_name = 'Reorder Refund')\n",
    "refund3 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2023.xlsx', sheet_name = 'Reorder Refund')\n",
    "refund4 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2024.xlsx', sheet_name = 'Refund Reseller')\n",
    "# \"D:\\6. settlement\\Code\\Settlement Project\\Nutrimart\\Settlement\\Transaksi Nutrimart 2024 .xlsx\"\n",
    "\n",
    "\n",
    "refund2 = refund2.rename(columns = {'Id Order Lama' : 'Id  Order lama', 'Id  Order Baru' : 'Id Order Baru'})\n",
    "refund3 = refund3.rename(columns = {'Id Order Lama' : 'Id  Order lama', 'Id  Order Baru' : 'Id Order Baru'})\n",
    "refund4 = refund4.rename(columns = {'Id Order Lama' : 'Id  Order lama', 'Id  Order Baru' : 'Id Order Baru'})\n",
    "\n",
    "refund1['Source'] = '2021'\n",
    "refund2['Source'] = '2022'\n",
    "refund3['Source'] = '2023'\n",
    "refund4['Source'] = '2024'\n",
    "\n",
    "refund = refund1.append(refund2, ignore_index = True, sort = False).append(refund3, ignore_index = True, sort = False).append(refund4, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#run 19.1\n",
    "# reorder=refund[(refund['Refund/ Reorder'].str.contains('reorder',case=False,na=False))&\n",
    "#                (refund['Id Order Baru'].notnull())] #komen feb 2022\n",
    "reorder=refund[(refund['Id Order Baru'].notnull())] \n",
    "# refund.columns\n",
    "reorder['Id Order Baru']=reorder['Id Order Baru'].astype(str)\n",
    "reorder['Id Order Baru']=reorder['Id Order Baru'].str.replace('\\.0','')\n",
    "reorder=reorder['Id Order Baru'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id  Order Baru Original</th>\n",
       "      <th>Id Order Lama Original</th>\n",
       "      <th>Refund/ Reorder</th>\n",
       "      <th>Note</th>\n",
       "      <th>Potensi BAA</th>\n",
       "      <th>Id Order Baru</th>\n",
       "      <th>Id  Order lama</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id  Order Baru Original, Id Order Lama Original, Refund/ Reorder, Note, Potensi BAA, Id Order Baru, Id  Order lama, Source]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking\n",
    "dups = refund1['Id  Order lama'].unique()\n",
    "refund2[refund2['Id  Order lama'].isin(dups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### run 20\n",
    "nutrimart_vou['Paid'] = np.nan\n",
    "\n",
    "# refund = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'Reorder Refund')\n",
    "refund['Id  Order lama'] = refund['Id  Order lama'].astype(str).str.strip()\n",
    "\n",
    "cancel = refund[refund['Refund/ Reorder'].astype(str).str.lower() == 'reorder']\n",
    "refund = refund[~refund['Id  Order lama'].isin(cancel['Id  Order lama'])]\n",
    "\n",
    "indeks = nutrimart_vou[nutrimart_vou['Order #'].isin(cancel['Id  Order lama'].unique())].index.to_list()\n",
    "nutrimart_vou['Paid'][indeks] = 'Cancel'\n",
    "\n",
    "indeks = nutrimart_vou[nutrimart_vou['Order #'].isin(refund['Id  Order lama'].unique())].index.to_list()\n",
    "nutrimart_vou['Paid'][indeks] = 'Cancel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nutrimart_vou#[nutrimart_vou['Order #']=='1000100177'][['Order #','Real SKU','Paid','Coupon Code','Pemilik Budget']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midtrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 NutriMart-Midtrans (Feb).csv\n",
      "1 NutriMart-Midtrans (Jan).csv\n",
      "10 NutriMart-Midtrans (Oct).csv\n",
      "11 NutriMart-Midtrans (Nov).csv\n",
      "12 Nutrimart-Midtrans (Des).csv\n",
      "13 NutriMart-Midtrans (Jan).csv\n",
      "14 NutriMart-Midtrans (Feb).csv\n",
      "15 NutriMart-Midtrans (Mar).csv\n",
      "16 NutriMart-Midtrans (Apr).csv\n",
      "17 NutriMart-Midtrans (Mei).csv\n",
      "18 NutriMart-Midtrans (Jun).csv\n",
      "19 NutriMart-Midtrans (Jul).csv\n",
      "20 NutriMart-Midtrans (Aug).csv\n",
      "3 NutriMart-Midtrans (Mar).csv\n",
      "4 NutriMart-Midtrans (Apr).csv\n",
      "5 NutriMart-Midtrans (Mei).csv\n",
      "6 NutriMart-Midtrans (Jun).csv\n",
      "7 NutriMart-Midtrans (Jul).csv\n",
      "8 NutriMart-Midtrans (Aug).csv\n",
      "9 NutriMart-Midtrans (Sep).csv\n",
      "NutriMart- MIdtrans (Jul).csv\n",
      "NutriMart- MIdtrans (Jun).csv\n",
      "NutriMart- Midtrans (Mar).csv\n",
      "NutriMart- Midtrans (Mei).csv\n",
      "NutriMart-Midtrans (Apr).csv\n",
      "NutriMart-Midtrans (Aug).csv\n",
      "NutriMart-Midtrans (Dec).csv\n",
      "NutriMart-Midtrans (Jan-feb).csv\n",
      "NutriMart-Midtrans (Nov).csv\n",
      "NutriMart-Midtrans (Oct).csv\n",
      "NutriMart-Midtrans (Sept).csv\n",
      "105\n",
      "[13688]\n",
      "13688    1000098196\n",
      "Name: Order ID, dtype: object\n",
      "106\n",
      "[13344]\n",
      "13344    1000098234\n",
      "Name: Order ID, dtype: object\n",
      "107\n",
      "[13965]\n",
      "13965    1000098289\n",
      "Name: Order ID, dtype: object\n",
      "108\n",
      "[14310]\n",
      "14310    1000098314\n",
      "Name: Order ID, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 21\n",
    "import pandas as pd\n",
    "import os\n",
    "midtrans1 = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'Midtrans', header = None)\n",
    "\n",
    "midtrans2 = pd.DataFrame()\n",
    "\n",
    "for i in os.listdir('Settlement Project/Nutrimart/Settlement/Midtrans/'):\n",
    "    print(i)\n",
    "    if 'xlsx' in i:\n",
    "        temp = pd.DataFrame()\n",
    "    else:\n",
    "        temp = pd.read_csv('Settlement Project/Nutrimart/Settlement/Midtrans/' + str(i))\n",
    "    temp['Source'] = i\n",
    "    midtrans2 = midtrans2.append(temp, ignore_index = True, sort = False)\n",
    "    midtrans2['Order ID'] = midtrans2['Order ID'].astype(str).str.replace(\"'\", '', regex = False)\n",
    "    if 'Channel' in midtrans2.columns:\n",
    "        midtrans2['Payment Type']=midtrans2['Channel']\n",
    "        \n",
    "        \n",
    "salah = pd.read_excel(r'Settlement Project/Nutrimart/Midtrans Salah.xlsx')\n",
    "salah['Order Salah'] = salah['Order Salah'].astype(str)\n",
    "midtrans2['Order ID'] = midtrans2['Order ID'].astype(str)\n",
    "for i in range(len(salah)):\n",
    "    print(salah['Order Salah'][i])\n",
    "    indeks = midtrans2[midtrans2['Order ID'] == salah['Order Salah'][i]].index.to_list()\n",
    "    print(indeks)\n",
    "    midtrans2['Order ID'][indeks]  = salah['Order Benar'][i]\n",
    "    print(midtrans2['Order ID'][indeks])\n",
    "\n",
    "midtrans2_copy=midtrans2.copy()\n",
    "midtrans2 = midtrans2[['Order ID', 'Transaction status', 'Amount','Payment Type']]\n",
    "midtrans2 = midtrans2.rename(columns = {'Order ID' : 1,'Payment Type':2, 'Amount' : 3})\n",
    "\n",
    "midtrans = midtrans1.append(midtrans2, ignore_index = True, sort = False)\n",
    "# midtrans[1]=midtrans[1].astype(int)#\n",
    "midtrans['Transaction status'] = midtrans['Transaction status'].fillna('settlement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Transaction status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13082</th>\n",
       "      <td>NaN</td>\n",
       "      <td>rRQSPb7DTaX7c9biCDgpByIpb</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>4963902.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>settlement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                          1            2          3    4    5    6  \\\n",
       "13082  NaN  rRQSPb7DTaX7c9biCDgpByIpb  Credit Card  4963902.0  NaN  NaN  NaN   \n",
       "\n",
       "      Transaction status  \n",
       "13082         settlement  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# midtrans[midtrans[1]=='rRQSPb7DTaX7c9biCDgpByIpb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking\n",
    "dups = midtrans2[1].unique()\n",
    "midtrans1[midtrans1[1].isin(dups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Transaction status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12037</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ORDER-101-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0           1    2        3    4    5    6 Transaction status\n",
       "12037  NaN  ORDER-101-  NaN  10000.0  NaN  NaN  NaN            failure"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run 21.1 midtrans ada '-' nya . must null\n",
    "midtrans.loc[midtrans[1].str.contains('-',na=False),1]=midtrans.loc[midtrans[1].str.contains('-',na=False)][1].str[:10]\n",
    "midtrans.loc[midtrans[1].str.contains('-',na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run 22\n",
    "all_cancel = pd.DataFrame()\n",
    "all_cancel['Order #'] = np.nan\n",
    "\n",
    "temp_cancel = midtrans[midtrans['Transaction status'] == 'failure']\n",
    "temp_cancel = temp_cancel.rename(columns = {1 : 'Order #'}) ## komen timo mar 23\n",
    "all_cancel = all_cancel.append(temp_cancel[['Order #']], ignore_index = True, sort = False)\n",
    "\n",
    "midtrans = midtrans[midtrans['Transaction status'].isin(['settlement','paid','success']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Transaction status</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Real Order #</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12155</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ruyWXAnmIUNhn3189DQSwAh3M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145177.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>settlement</td>\n",
       "      <td>#2218</td>\n",
       "      <td>145177</td>\n",
       "      <td>#2218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                          1    2         3    4    5    6  \\\n",
       "12155  NaN  ruyWXAnmIUNhn3189DQSwAh3M  NaN  145177.0  NaN  NaN  NaN   \n",
       "\n",
       "      Transaction status Order #  Amount Real Order #  \n",
       "12155         settlement   #2218  145177        #2218  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midtrans[midtrans['Order #']=='#2218']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Transaction status</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6, Transaction status, Order #, Amount]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 23\n",
    "\n",
    "midtrans['Order #'] = midtrans[1].astype(str).str.strip()\n",
    "\n",
    "### tambahan timo oct 2022\n",
    "midtrans[\"Order # kiri\"]= midtrans[1].str.split('-', expand = True)[0]\n",
    "midtrans.loc[midtrans[\"Order # kiri\"].notnull(),'Order #']=midtrans[\"Order # kiri\"]\n",
    "midtrans.drop(columns =[\"Order # kiri\"], inplace = True)\n",
    "# midtrans=midtrans.reset_index(drop=True)\n",
    "### tambahan timo oct 2022\n",
    "\n",
    "\n",
    "midtrans['Amount'] = pd.to_numeric(midtrans[3].astype(str).str.replace('.00 CR','', regex = False).str.replace('Rp.','', regex = False).str.replace(',','', regex = False).str.replace(' ','', regex = False), errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "indeks = midtrans[midtrans['Order #'].astype(str).str.contains('/', regex = False)].index.to_list()\n",
    "midtrans['Order #'][indeks] = midtrans['Order #'][indeks].astype(str).str.split('/', expand = True)[1]\n",
    "display(midtrans[(midtrans[1].notnull())&(midtrans['Order #'].isnull())])\n",
    "\n",
    "cancel['Id  Order lama'] = cancel['Id  Order lama'].astype(str).str.strip()\n",
    "\n",
    "\n",
    "# print(midtrans[midtrans['Order #']=='1000115145'].index[0])\n",
    "midtrans_reorder = midtrans.merge(cancel.drop_duplicates('Id  Order lama'), how = 'left', left_on = 'Order #', right_on = 'Id  Order lama').set_index(midtrans.index)\n",
    "# print(midtrans_reorder[midtrans_reorder['Order #']=='1000115145'].index[0])\n",
    "indeks = midtrans_reorder[midtrans_reorder['Id  Order lama'].notnull()].index.to_list()\n",
    "# display(midtrans_reorder[midtrans_reorder['Id  Order lama'].notnull()])\n",
    "midtrans['Order #'][indeks] = midtrans_reorder['Id Order Baru'][indeks]\n",
    "\n",
    "midtrans.loc[(midtrans[1].notnull())&(midtrans['Order #'].isnull()),'Order #']=midtrans[1].astype(str).str.strip() #timo feb 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Transaction status</th>\n",
       "      <th>Order #</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6, Transaction status, Order #, Amount]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## must null\n",
    "display(midtrans[(midtrans[1].notnull())&(midtrans['Order #'].isnull())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nutrimart_vou\n",
    "# midtrans[midtrans[1].str.contains('#',na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "0\n",
      "=============\n",
      "Bank Transfer\n",
      "193\n",
      "=============\n",
      "GO-PAY\n",
      "12\n",
      "=============\n",
      "Mandiri Bill\n",
      "29\n",
      "=============\n",
      "QRIS\n",
      "54\n",
      "=============\n",
      "Credit Card\n",
      "91\n",
      "=============\n",
      "ShopeePay\n",
      "1\n",
      "=============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## run 24\n",
    "\n",
    "#timo 2024\n",
    "shopifycp=shopify[['Payment References','Name']].drop_duplicates('Payment References')\n",
    "shopifycp['Order #']=shopifycp['Payment References']\n",
    "shopifycp['Real Order #']=shopifycp['Name']\n",
    "if 'Real Order #' not in midtrans.columns:\n",
    "    midtrans=midtrans.merge(shopifycp[['Order #','Real Order #']],how='left')\n",
    "midtrans.loc[midtrans['Real Order #'].notnull(),'Order #']=midtrans[midtrans['Real Order #'].notnull()]['Real Order #']\n",
    "\n",
    "for i in midtrans[midtrans['Real Order #'].notnull()][2].unique():\n",
    "    ordtemp=midtrans[(midtrans[2]==i)&(midtrans['Real Order #'].notnull())]['Real Order #'].unique()\n",
    "    nutrimart_vou.loc[nutrimart_vou['Order #'].isin(ordtemp),'Payment Channel']=i\n",
    "    print(i)\n",
    "    print(len(ordtemp))\n",
    "    print(\"=============\")\n",
    "#########\n",
    "\n",
    "\n",
    "\n",
    "nutrimart_midtrans = nutrimart_vou[nutrimart_vou['Order #'].isin(midtrans['Order #'].astype(str))]\n",
    "non_midtrans = nutrimart_vou[~nutrimart_vou['Order #'].isin(nutrimart_midtrans['Order #'].astype(str))]\n",
    "\n",
    "nutrimart_real = nutrimart_midtrans[nutrimart_midtrans['Bundle Name'].isnull()]\n",
    "nutrimart_bundle = nutrimart_midtrans[nutrimart_midtrans['Bundle Name'].notnull()]\n",
    "\n",
    "nutrimart_real['Order #'] = nutrimart_real['Order #'].astype(str).str.strip()\n",
    "midtrans['Order #'] = midtrans['Order #'].astype(str).str.strip()\n",
    "\n",
    "midtrans_short = midtrans[['Order #', 'Amount']].drop_duplicates('Order #')\n",
    "\n",
    "\n",
    "\n",
    "nutrimart_midtrans = nutrimart_real.merge(midtrans_short, how = 'left', on = 'Order #')\n",
    "nutrimart_midtrans['Amount'] = nutrimart_midtrans['Amount'].fillna(0) * nutrimart_midtrans['Total Net Before PPN']/nutrimart_midtrans.groupby(['Order #'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'] = np.nan\n",
    "\n",
    "### mapping payment channel lain\n",
    "       \n",
    "\n",
    "indeks = nutrimart_midtrans[nutrimart_midtrans['Payment Channel'].isin([\n",
    "    'snap_mandiri_bill_payment', 'snap_banktransfer', 'snap_banktransfer_permata',\n",
    "    'snap_banktransfer_bca', 'payment_subcription','snap_creditcardbin','Bank Transfer', 'Mandiri Bill'\n",
    "])].index.to_list()\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'][indeks] = 4400\n",
    "\n",
    "indeks = nutrimart_midtrans[nutrimart_midtrans['Payment Channel'].isin([\n",
    "    'snap_cimbclicks',\n",
    "])].index.to_list()\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'][indeks] = 5000\n",
    "\n",
    "indeks = nutrimart_midtrans[nutrimart_midtrans['Payment Channel'].isin([\n",
    "    'snap_bcaklikpay',\n",
    "])].index.to_list()\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'][indeks] = 2500\n",
    "\n",
    "######\n",
    "sum_payfee = nutrimart_midtrans[nutrimart_midtrans['Payment Channel'].isin([\n",
    "    'snap_gopay','GO-PAY'\n",
    "])]\n",
    "\n",
    "sum_payfee = sum_payfee.drop('Payment Fee', axis = 1)\n",
    "sum_payfee['Payment Fee'] = sum_payfee.groupby(['Order #'])['Amount'].transform('sum') * 0.02\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'][sum_payfee.index] = sum_payfee['Payment Fee']\n",
    "\n",
    "######\n",
    "\n",
    "sum_payfee = nutrimart_midtrans[nutrimart_midtrans['Payment Channel'].isin([\n",
    "    'snap_shopeepay','ShopeePay'\n",
    "])]\n",
    "\n",
    "sum_payfee = sum_payfee.drop('Payment Fee', axis = 1)\n",
    "sum_payfee['Payment Fee'] = sum_payfee.groupby(['Order #'])['Amount'].transform('sum') * 0.015\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'][sum_payfee.index] = sum_payfee['Payment Fee']\n",
    "\n",
    "######\n",
    "sum_payfee = nutrimart_midtrans[nutrimart_midtrans['Payment Channel'].isin([\n",
    "    'QRIS'\n",
    "])]\n",
    "\n",
    "sum_payfee = sum_payfee.drop('Payment Fee', axis = 1)\n",
    "sum_payfee['Payment Fee'] = sum_payfee.groupby(['Order #'])['Amount'].transform('sum') * 0.007\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'][sum_payfee.index] = sum_payfee['Payment Fee']\n",
    "\n",
    "######\n",
    "sum_payfee = nutrimart_midtrans[nutrimart_midtrans['Payment Channel'].isin([\n",
    "    'Credit Card','snap_creditcard'\n",
    "])]\n",
    "\n",
    "sum_payfee = sum_payfee.drop('Payment Fee', axis = 1)\n",
    "sum_payfee['Payment Fee'] = sum_payfee.groupby(['Order #'])['Amount'].transform('sum') * 0.029+2000\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'][sum_payfee.index] = sum_payfee['Payment Fee']\n",
    "\n",
    "#####\n",
    "sum_payfee = nutrimart_midtrans[nutrimart_midtrans['Payment Channel'].isin([\n",
    "    'snap_mandiri_installment', 'snap', 'snap_creditcard_mandiri'\n",
    "])]\n",
    "\n",
    "sum_payfee = sum_payfee.drop('Payment Fee', axis = 1)\n",
    "sum_payfee['Payment Fee'] = sum_payfee.groupby(['Order #'])['Amount'].transform('sum') * 0.03\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'][sum_payfee.index] = sum_payfee['Payment Fee']\n",
    "\n",
    "nutrimart_midtrans['Payment Fee'] = nutrimart_midtrans['Payment Fee'].fillna(0) * nutrimart_midtrans['Total Net Before PPN']/nutrimart_midtrans.groupby(['Order #'])['Total Net Before PPN'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nutrimart_midtrans[nutrimart_midtrans[\"Order #\"]=='#2218']['Payment Channel']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "### run 25\n",
    "\n",
    "indeks = nutrimart_midtrans[nutrimart_midtrans['Paid'].isin(['Refund', 'Cancel'])].index.to_list()\n",
    "nutrimart_midtrans['Amount'][indeks] = 0\n",
    "nutrimart_midtrans['Payment Fee'][indeks] = 0\n",
    "\n",
    "bundle_merge = nutrimart_bundle.merge(nutrimart_midtrans[['Order #', 'Product Name','Amount', 'Payment Fee']].drop_duplicates(['Order #', 'Product Name']), how = 'left', \n",
    "                                 left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "bundle_merge = bundle_merge.rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "bundle_merge = bundle_merge.drop('Product Name_y', axis = 1)\n",
    "\n",
    "bundle_merge['Amount'] = bundle_merge['Amount'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "bundle_merge['Payment Fee'] = bundle_merge['Payment Fee'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_midtrans = nutrimart_midtrans.append(bundle_merge, ignore_index = True, sort = False)\n",
    "\n",
    "nutrimart_midtrans['FullFee'] = 0\n",
    "nutrimart_midtrans['Total Produk'] = pd.to_numeric(nutrimart_midtrans['Amount']).fillna(0).astype('int64')\n",
    "\n",
    "nutrimart_aft_midtrans = nutrimart_midtrans.append(non_midtrans, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total Net               29051030.0\n",
       "Amount                  15927052.0\n",
       "Payment Fee     318541.04000000004\n",
       "Total Produk            15927013.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real Nama Produk</th>\n",
       "      <th>Total Net</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Payment Fee</th>\n",
       "      <th>Total Produk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Real Nama Produk, Total Net, Amount, Payment Fee, Total Produk]\n",
       "Index: []"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrimart_midtrans[nutrimart_midtrans['Order #'] == '1000103625'][['Real Nama Produk','Total Net','Amount', 'Payment Fee', 'Total Produk']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 NutriMart-Ovo (Feb).xls\n",
      "1 NutriMart-Ovo (Jan).xls\n",
      "10 NutriMart-Ovo (Oct).xls\n",
      "11 NutriMart-Ovo (Nov).xls\n",
      "12 NutriMart-Ovo (Des).xls\n",
      "13 NutriMart-Ovo (Jan).xls\n",
      "14 NutriMart-Ovo (Feb).xls\n",
      "15 NutriMart-Ovo (Mar).xls\n",
      "16 NutriMart-Ovo (Apr).xls\n",
      "3 NutriMart-Ovo (Mar).xls\n",
      "4 NutriMart-Ovo (Apr).xls\n",
      "5 NutriMart-Ovo (Mei).xls\n",
      "6 NutriMart-Ovo (Jun).xls\n",
      "7 NutriMart-Ovo (Jul).xls\n",
      "8 NutriMart-Ovo (Aug).xls\n",
      "9 NutriMart-Ovo (Sep).xls\n",
      "NutriMart-Ovo (Apr).xls\n",
      "NutriMart-Ovo (Aug).xls\n",
      "NutriMart-Ovo (Dec).xls\n",
      "NutriMart-Ovo (Jan-Feb).xls\n",
      "NutriMart-Ovo (Jul).xls\n",
      "NutriMart-Ovo (Jun).xls\n",
      "NutriMart-Ovo (Mar).xls\n",
      "NutriMart-Ovo (Mei).xls\n",
      "NutriMart-Ovo (Nov).xls\n",
      "NutriMart-Ovo (Oct).xls\n",
      "NutriMart-Ovo (Sept).xls\n"
     ]
    }
   ],
   "source": [
    "## run 26\n",
    "ovo1 = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'OVO')\n",
    "\n",
    "ovo2 = pd.DataFrame()\n",
    "\n",
    "for i in os.listdir('Settlement Project/Nutrimart/Settlement/Ovo/'):\n",
    "    print(i)\n",
    "    temp = pd.read_html('Settlement Project/Nutrimart/Settlement/Ovo/' + str(i), header = 0)\n",
    "    temp = temp[0]\n",
    "    temp = temp.rename(columns = {'Reference No' : 'IdOrder', 'Amount' : 'Nominal'})\n",
    "    ovo2 = ovo2.append(temp, ignore_index = True, sort = False)\n",
    "    \n",
    "\n",
    "ovo2 = ovo2[['IdOrder', 'Nominal', 'Status']]\n",
    "ovo2 = ovo2[~ovo2['IdOrder'].isin(ovo1['IdOrder'])]\n",
    "ovo = ovo1.append(ovo2, ignore_index = True, sort = False)\n",
    "\n",
    "ovo['Status'] = ovo['Status'].fillna('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IdOrder</th>\n",
       "      <th>Nominal</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [IdOrder, Nominal, Status]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking\n",
    "dups = ovo1['IdOrder'].unique()\n",
    "ovo2[ovo2['IdOrder'].isin(dups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 27\n",
    "temp_cancel = ovo[ovo['Status'] == 'Fail']\n",
    "temp_cancel = temp_cancel.rename(columns = {'IdOrder' : 'Order #'})\n",
    "all_cancel = all_cancel.append(temp_cancel[['Order #']], ignore_index = True, sort = False)\n",
    "\n",
    "ovo = ovo[ovo['Status'] == 'Success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "### run 28\n",
    "ovo['Order #'] = ovo['IdOrder'].astype(str).str.strip().str.replace('.0', '', regex = False)\n",
    "ovo['Amount'] = pd.to_numeric(ovo['Nominal'], errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "cancel['Id  Order lama'] = cancel['Id  Order lama'].astype(str).str.strip()\n",
    "\n",
    "ovo_reorder = ovo.merge(cancel.drop_duplicates('Id  Order lama'), how = 'left', left_on = 'Order #', right_on = 'Id  Order lama')\n",
    "indeks = ovo_reorder[ovo_reorder['Id  Order lama'].notnull()].index.to_list()\n",
    "ovo['Order #'][indeks] = ovo_reorder['Id Order Baru'][indeks]\n",
    "\n",
    "ovo['Order #'] = ovo['Order #'].astype(str).str.strip().replace('.0', '', regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 29\n",
    "nutrimart_ovo = nutrimart_aft_midtrans[nutrimart_aft_midtrans['Order #'].isin(ovo['Order #'].astype(str))]\n",
    "non_ovo = nutrimart_aft_midtrans[~nutrimart_aft_midtrans['Order #'].isin(ovo['Order #'].astype(str))]\n",
    "\n",
    "nutrimart_ovo = nutrimart_ovo.drop(['Amount', 'Payment Fee'], axis = 1)\n",
    "\n",
    "nutrimart_real = nutrimart_ovo[nutrimart_ovo['Bundle Name'].isnull()]\n",
    "nutrimart_bundle = nutrimart_ovo[nutrimart_ovo['Bundle Name'].notnull()]\n",
    "\n",
    "nutrimart_real['Order #'] = nutrimart_real['Order #'].astype(str).str.strip()\n",
    "ovo['Order #'] = ovo['Order #'].astype(str).str.strip()\n",
    "ovo_short = ovo[['Order #', 'Amount']].drop_duplicates('Order #')\n",
    "\n",
    "nutrimart_ovo = nutrimart_real.merge(ovo_short, how = 'left', on = 'Order #')\n",
    "nutrimart_ovo['Amount'] = nutrimart_ovo['Amount'].fillna(0) * nutrimart_ovo['Total Net Before PPN']/nutrimart_ovo.groupby(['Order #'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_ovo['Payment Fee'] = 0\n",
    "\n",
    "sum_payfee = nutrimart_ovo[nutrimart_ovo['Payment Channel'].isin([\n",
    "    'ipay88_ovo'\n",
    "])]\n",
    "\n",
    "sum_payfee = sum_payfee.drop('Payment Fee', axis = 1)\n",
    "sum_payfee['Payment Fee'] = sum_payfee.groupby(['Order #'])['Amount'].transform('sum') * 0.01647\n",
    "\n",
    "nutrimart_ovo['Payment Fee'][sum_payfee.index] = sum_payfee['Payment Fee']\n",
    "\n",
    "indeks = nutrimart_ovo[nutrimart_ovo['Paid'].isin(['Refund', 'Cancel'])].index.to_list()\n",
    "nutrimart_ovo['Amount'][indeks] = 0\n",
    "nutrimart_ovo['Payment Fee'][indeks] = 0\n",
    "\n",
    "bundle_merge = nutrimart_bundle.merge(nutrimart_ovo[['Order #', 'Product Name','Amount', 'Payment Fee']].drop_duplicates(['Order #', 'Product Name']), how = 'left', \n",
    "                                 left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "bundle_merge = bundle_merge.rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "bundle_merge = bundle_merge.drop('Product Name_y', axis = 1)\n",
    "\n",
    "bundle_merge['Amount'] = bundle_merge['Amount'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "# bundle_merge['Payment Fee'] = bundle_merge['Payment Fee'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_ovo = nutrimart_ovo.append(bundle_merge, ignore_index = True, sort = False)\n",
    "\n",
    "nutrimart_ovo['FullFee'] = 0\n",
    "nutrimart_ovo['Total Produk'] = pd.to_numeric(nutrimart_ovo['Amount']).fillna(0).astype('int64')\n",
    "\n",
    "nutrimart_aft_ovo = nutrimart_ovo.append(non_ovo, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "### run 30\n",
    "cod = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'COD')\n",
    "\n",
    "cod['Order #'] = cod['Id Order'].astype(str).str.strip()\n",
    "cod['Amount'] = pd.to_numeric(cod['Nominal'], errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "cancel['Id  Order lama'] = cancel['Id  Order lama'].astype(str).str.strip()\n",
    "\n",
    "cod_reorder = cod.merge(cancel.drop_duplicates('Id  Order lama'), how = 'left', left_on = 'Order #', right_on = 'Id  Order lama')\n",
    "indeks = cod_reorder[cod_reorder['Id  Order lama'].notnull()].index.to_list()\n",
    "cod['Order #'][indeks] = cod_reorder['Id Order Baru'][indeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDD0000232963-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000233552-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000235898-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000237543-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000238300-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000238976-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000240849-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000241554-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000242262-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000243285-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000243757-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000246250-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000246896-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000248462-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000249178-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000251452-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000253074-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000253624-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000258099-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000260743-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000262151-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000263582-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000264134-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000264806-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000267641-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000268076-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000274057-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000275308-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000277829-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000279302-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000280521-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000282011-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000295152-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000301507-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000303414-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000304654-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000306577-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MDD0000311987-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MTC0000214304-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MTC0000216389-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MTC197636-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MTC204072-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n",
      "MTC213375-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\n"
     ]
    }
   ],
   "source": [
    "## run 30.1\n",
    "dfcod=pd.read_excel(r\"Settlement Project\\Nutrimart\\Settlement\\COD\\MTC197636-NUTRIFOOD_INDONESIA_PT__COD_-BAYAR.xlsx\")\n",
    "newcod=pd.DataFrame()\n",
    "for file in os.listdir(r'Settlement Project\\Nutrimart\\Settlement\\COD'):\n",
    "    print(file)\n",
    "    tempcod=pd.read_excel(fr'Settlement Project\\Nutrimart\\Settlement\\COD/{file}')\n",
    "    if 'Nilai COD' in tempcod.columns:\n",
    "        tempcod=tempcod.rename(columns={'Nilai COD':'Value Setor'})\n",
    "    if 'AWB' in tempcod.columns:\n",
    "        tempcod=tempcod.rename(columns={'AWB':'No. AWB'})\n",
    "    # print(tempcod.columns)\n",
    "    tempcod=tempcod[tempcod['No'].notnull()]\n",
    "    tempcod['TOTAL COD FEE']=tempcod['Value Setor']*0.02\n",
    "    tempcod['Order #']=tempcod['No. AWB'].str.replace('NTRM','')\n",
    "    newcod=newcod.append(tempcod)\n",
    "newcod['Id Order']=newcod['Order #']\n",
    "newcod['Nominal']=newcod['TOTAL COD FEE']\n",
    "newcod['Amount']=newcod['TOTAL COD FEE']\n",
    "newcod['Nama Konsumen']=newcod['Nama Penerima']\n",
    "newcod['Mutasi']='COD'\n",
    "# newcod=newcod[['Order #','Value Setor','TOTAL COD FEE','Nama Penerima']].rename(columns={'Order #','Value Setor','TOTAL COD FEE','Nama Penerima'})\n",
    "codappend=cod.append(newcod)[cod.columns].reset_index(drop=True)\n",
    "# newcod\n",
    "cod=codappend.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 31\n",
    "nutrimart_cod = nutrimart_aft_ovo[nutrimart_aft_ovo['Order #'].isin(cod['Order #'].astype(str))]\n",
    "non_cod = nutrimart_aft_ovo[~nutrimart_aft_ovo['Order #'].isin(cod['Order #'].astype(str))]\n",
    "\n",
    "nutrimart_cod = nutrimart_cod.drop(['Amount', 'Payment Fee'], axis = 1)\n",
    "\n",
    "nutrimart_real = nutrimart_cod[nutrimart_cod['Bundle Name'].isnull()]\n",
    "nutrimart_bundle = nutrimart_cod[nutrimart_cod['Bundle Name'].notnull()]\n",
    "\n",
    "nutrimart_real['Order #'] = nutrimart_real['Order #'].astype(str).str.strip()\n",
    "cod['Order #'] = cod['Order #'].astype(str).str.strip()\n",
    "cod_short = cod[['Order #', 'Amount']].drop_duplicates('Order #')\n",
    "\n",
    "nutrimart_cod = nutrimart_real.merge(cod_short, how = 'left', on = 'Order #')\n",
    "nutrimart_cod['Amount'] = nutrimart_cod['Amount'].fillna(0) * nutrimart_cod['Total Net Before PPN']/nutrimart_cod.groupby(['Order #'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_cod['Payment Fee'] = nutrimart_cod.groupby(['Order #'])['Amount'].transform('sum') * 0.03\n",
    "nutrimart_cod['Payment Fee'] = nutrimart_cod['Payment Fee'].fillna(0) * nutrimart_cod['Total Net Before PPN']/nutrimart_cod.groupby(['Order #'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "indeks = nutrimart_cod[nutrimart_cod['Paid'].isin(['Refund', 'Cancel'])].index.to_list()\n",
    "nutrimart_cod['Amount'][indeks] = 0\n",
    "nutrimart_cod['Payment Fee'][indeks] = 0\n",
    "\n",
    "bundle_merge = nutrimart_bundle.merge(nutrimart_cod[['Order #', 'Product Name','Amount', 'Payment Fee']].drop_duplicates(['Order #', 'Product Name']), how = 'left', \n",
    "                                 left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "bundle_merge = bundle_merge.rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "bundle_merge = bundle_merge.drop('Product Name_y', axis = 1)\n",
    "\n",
    "bundle_merge['Amount'] = bundle_merge['Amount'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "bundle_merge['Payment Fee'] = bundle_merge['Payment Fee'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_cod = nutrimart_cod.append(bundle_merge, ignore_index = True, sort = False)\n",
    "\n",
    "nutrimart_cod['FullFee'] = 0\n",
    "nutrimart_cod['Total Produk'] = pd.to_numeric(nutrimart_cod['Amount']).fillna(0).astype('int64')\n",
    "\n",
    "nutrimart_aft_cod = nutrimart_cod.append(non_cod, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nutrimart_aft_cod[nutrimart_aft_cod['Order #'] == '1000097863']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Manual BCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 32\n",
    "transman1 = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'BCA (0943660708)')\n",
    "transman2 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2022 (New Format).xlsx', sheet_name = 'BCA (0708)')\n",
    "transman3 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2023.xlsx', sheet_name = 'BCA (0708)')\n",
    "transman4 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2024.xlsx', sheet_name = 'BCA (0708)')\n",
    "\n",
    "# transman2 = transman2.rename(columns = {'Id Order Lama' : 'Id  Order lama', 'Id  Order Baru' : 'Id Order Baru', })\n",
    "transman1['Source'] = '2021'\n",
    "transman2['Source'] = '2022'\n",
    "transman3['Source'] = '2023'\n",
    "transman3['Source'] = '2024'\n",
    "\n",
    "if 'IDOrder' in transman2.columns:\n",
    "    transman2=transman2.rename(columns={'IDOrder':'ID Order'})\n",
    "if 'IDOrder' in transman3.columns:\n",
    "    transman3=transman3.rename(columns={'IDOrder':'ID Order'})\n",
    "if 'IDOrder' in transman4.columns:\n",
    "    transman4=transman4.rename(columns={'IDOrder':'ID Order'})\n",
    "    \n",
    "\n",
    "transman2 = transman2[~transman2['ID Order'].isin(transman1['ID Order'])]\n",
    "transman3 = transman3[~transman3['ID Order'].isin(transman2['ID Order'])]\n",
    "transman4 = transman4[~transman4['ID Order'].isin(transman3['ID Order'])]\n",
    "\n",
    "transman = transman1.append(transman2, ignore_index = True, sort = False).append(transman3, ignore_index = True, sort = False).append(transman4, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transman3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "### run 33\n",
    "transman['Order #'] = transman['ID Order'].astype(str).str.strip()\n",
    "transman['Amount'] = pd.to_numeric(transman[617].astype(str).str.replace('.00 CR','', regex = False).str.replace('.00','', regex = False).str.replace(',','', regex = False).str.replace(' ','', regex = False), errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "cancel['Id  Order lama'] = cancel['Id  Order lama'].astype(str).str.strip()\n",
    "\n",
    "transman_reorder = transman.merge(cancel.drop_duplicates('Id  Order lama'), how = 'left', left_on = 'Order #', right_on = 'Id  Order lama')\n",
    "indeks = transman_reorder[transman_reorder['Id  Order lama'].notnull()].index.to_list()\n",
    "transman['Order #'][indeks] = transman_reorder['Id Order Baru'][indeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 34\n",
    "nutrimart_transman = nutrimart_aft_cod[nutrimart_aft_cod['Order #'].isin(transman['Order #'].astype(str))]\n",
    "non_transman = nutrimart_aft_cod[~nutrimart_aft_cod['Order #'].isin(transman['Order #'].astype(str))]\n",
    "\n",
    "nutrimart_transman = nutrimart_transman.drop(['Amount', 'Payment Fee'], axis = 1)\n",
    "\n",
    "nutrimart_real = nutrimart_transman[nutrimart_transman['Bundle Name'].isnull()]\n",
    "nutrimart_bundle = nutrimart_transman[nutrimart_transman['Bundle Name'].notnull()]\n",
    "\n",
    "nutrimart_real['Order #'] = nutrimart_real['Order #'].astype(str)\n",
    "transman['Order #'] = transman['Order #'].astype(str)\n",
    "transman_short = transman[['Order #', 'Amount']].drop_duplicates('Order #')\n",
    "\n",
    "nutrimart_transman = nutrimart_real.merge(transman_short, how = 'left', on = 'Order #')\n",
    "nutrimart_transman['Amount'] = nutrimart_transman['Amount'].fillna(0) * nutrimart_transman['Total Net Before PPN']/nutrimart_transman.groupby(['Order #'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_transman['Payment Fee'] = 0\n",
    "\n",
    "indeks = nutrimart_transman[nutrimart_transman['Paid'].isin(['Refund', 'Cancel'])].index.to_list()\n",
    "nutrimart_transman['Amount'][indeks] = 0\n",
    "nutrimart_transman['Payment Fee'][indeks] = 0\n",
    "\n",
    "bundle_merge = nutrimart_bundle.merge(nutrimart_transman[['Order #', 'Product Name','Amount', 'Payment Fee']].drop_duplicates(['Order #', 'Product Name']), how = 'left', \n",
    "                                 left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "bundle_merge = bundle_merge.rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "bundle_merge = bundle_merge.drop('Product Name_y', axis = 1)\n",
    "\n",
    "bundle_merge['Amount'] = bundle_merge['Amount'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "# bundle_merge['Payment Fee'] = bundle_merge['Payment Fee'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_transman = nutrimart_transman.append(bundle_merge, ignore_index = True, sort = False)\n",
    "\n",
    "nutrimart_transman['FullFee'] = 0\n",
    "nutrimart_transman['Total Produk'] = pd.to_numeric(nutrimart_transman['Amount']).fillna(0).astype('int64')\n",
    "\n",
    "nutrimart_aft_transman = nutrimart_transman.append(non_transman, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nutrimart_transman[['Total Produk', 'Payment Fee']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nutrimart_aft_transman[nutrimart_aft_transman['Order #'] == '1000097863']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Manual Mandiri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run 35\n",
    "transmandiri1 = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'Mandiri')\n",
    "transmandiri2 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2022 (New Format).xlsx', sheet_name = 'Mandiri')\n",
    "transmandiri3 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2023.xlsx', sheet_name = 'MANDIRI')\n",
    "transmandiri4 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2024.xlsx', sheet_name = 'MANDIRI')\n",
    "# transmandiri2 = transmandiri2.rename(columns = {'Id Order Lama' : 'Id  Order lama', 'Id  Order Baru' : 'Id Order Baru', })\n",
    "\n",
    "transmandiri1['Source'] = '2021'\n",
    "transmandiri2['Source'] = '2022'\n",
    "transmandiri3['Source'] = '2023'\n",
    "transmandiri4['Source'] = '2024'\n",
    "\n",
    "transmandiri2 = transmandiri2[~transmandiri2['ID Order'].isin(transmandiri1['ID Order'])]\n",
    "transmandiri3 = transmandiri3[~transmandiri3['ID Order'].isin(transmandiri2['ID Order'])]\n",
    "transmandiri4 = transmandiri4[~transmandiri4['ID Order'].isin(transmandiri3['ID Order'])]\n",
    "\n",
    "transmandiri = transmandiri1.append(transmandiri2, ignore_index = True, sort = False).append(transmandiri3, ignore_index = True, sort = False).append(transmandiri4, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transmandiri2[transmandiri2['ID Order'].isin(transmandiri1['ID Order'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transmandiri2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "### run 36\n",
    "transmandiri['Order #'] = transmandiri['ID Order'].astype(str).str.strip()\n",
    "transmandiri['Amount'] = pd.to_numeric(transmandiri[617].astype(str).str.replace('.00 CR','', regex = False).str.replace('.00','', regex = False).str.replace(',','', regex = False).str.replace(' ','', regex = False), errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "cancel['Id  Order lama'] = cancel['Id  Order lama'].astype(str).str.strip()\n",
    "\n",
    "transmandiri_reorder = transmandiri.merge(cancel.drop_duplicates('Id  Order lama'), how = 'left', left_on = 'Order #', right_on = 'Id  Order lama')\n",
    "indeks = transmandiri_reorder[transmandiri_reorder['Id  Order lama'].notnull()].index.to_list()\n",
    "transmandiri['Order #'][indeks] = transmandiri_reorder['Id Order Baru'][indeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## run 37\n",
    "nutrimart_transmandiri = nutrimart_aft_transman[nutrimart_aft_transman['Order #'].isin(transmandiri['Order #'].astype(str))]\n",
    "non_transmandiri = nutrimart_aft_transman[~nutrimart_aft_transman['Order #'].isin(transmandiri['Order #'].astype(str))]\n",
    "\n",
    "nutrimart_transmandiri = nutrimart_transmandiri.drop(['Amount', 'Payment Fee'], axis = 1)\n",
    "\n",
    "nutrimart_real = nutrimart_transmandiri[nutrimart_transmandiri['Bundle Name'].isnull()]\n",
    "nutrimart_bundle = nutrimart_transmandiri[nutrimart_transmandiri['Bundle Name'].notnull()]\n",
    "\n",
    "nutrimart_real['Order #'] = nutrimart_real['Order #'].astype(str)\n",
    "transmandiri['Order #'] = transmandiri['Order #'].astype(str)\n",
    "transmandiri_short = transmandiri[['Order #', 'Amount']].drop_duplicates('Order #')\n",
    "\n",
    "nutrimart_transmandiri = nutrimart_real.merge(transmandiri_short, how = 'left', on = 'Order #')\n",
    "nutrimart_transmandiri['Amount'] = nutrimart_transmandiri['Amount'].fillna(0) * nutrimart_transmandiri['Total Net Before PPN']/nutrimart_transmandiri.groupby(['Order #'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_transmandiri['Payment Fee'] = 0\n",
    "\n",
    "indeks = nutrimart_transmandiri[nutrimart_transmandiri['Paid'].isin(['Refund', 'Cancel'])].index.to_list()\n",
    "nutrimart_transmandiri['Amount'][indeks] = 0\n",
    "nutrimart_transmandiri['Payment Fee'][indeks] = 0\n",
    "\n",
    "bundle_merge = nutrimart_bundle.merge(nutrimart_transmandiri[['Order #', 'Product Name','Amount', 'Payment Fee']].drop_duplicates(['Order #', 'Product Name']), how = 'left', \n",
    "                                 left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "bundle_merge = bundle_merge.rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "bundle_merge = bundle_merge.drop('Product Name_y', axis = 1)\n",
    "\n",
    "bundle_merge['Amount'] = bundle_merge['Amount'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "# bundle_merge['Payment Fee'] = bundle_merge['Payment Fee'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_transmandiri = nutrimart_transmandiri.append(bundle_merge, ignore_index = True, sort = False)\n",
    "\n",
    "nutrimart_transmandiri['FullFee'] = 0\n",
    "nutrimart_transmandiri['Total Produk'] = pd.to_numeric(nutrimart_transmandiri['Amount']).fillna(0).astype('int64')\n",
    "\n",
    "nutrimart_aft_transmandiri = nutrimart_transmandiri.append(non_transmandiri, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nutrimart_aft_transmandiri[nutrimart_aft_transmandiri['Order #'] == '1000097863']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanpa Bayar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 38\n",
    "tanpa_bayar1 = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'Rekap Tanpa Bayar')\n",
    "tanpa_bayar2 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2022 (New Format).xlsx', sheet_name = 'Rekap Tanpa Bayar')\n",
    "tanpa_bayar3 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2023.xlsx', sheet_name = 'Rekap Tanpa Bayar')\n",
    "tanpa_bayar4 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2024.xlsx', sheet_name = 'Rekap Tanpa Bayar')\n",
    "\n",
    "tanpa_bayar2 = tanpa_bayar2.rename(columns = {'ID Order' : 'IDOrder'})\n",
    "tanpa_bayar3 = tanpa_bayar3.rename(columns = {'ID Order' : 'IDOrder'})\n",
    "tanpa_bayar4 = tanpa_bayar4.rename(columns = {'ID Order' : 'IDOrder'})\n",
    "\n",
    "tanpa_bayar1['Source'] = '2021'\n",
    "tanpa_bayar2['Source'] = '2022'\n",
    "tanpa_bayar3['Source'] = '2023'\n",
    "tanpa_bayar4['Source'] = '2024'\n",
    "\n",
    "tanpa_bayar2 = tanpa_bayar2[~tanpa_bayar2['IDOrder'].isin(tanpa_bayar1['IDOrder'])]\n",
    "tanpa_bayar3 = tanpa_bayar3[~tanpa_bayar3['IDOrder'].isin(tanpa_bayar2['IDOrder'])]\n",
    "tanpa_bayar4 = tanpa_bayar4[~tanpa_bayar4['IDOrder'].isin(tanpa_bayar3['IDOrder'])]\n",
    "\n",
    "tanpa_bayar = tanpa_bayar1.append(tanpa_bayar2, ignore_index = True, sort = False).append(tanpa_bayar3, ignore_index = True, sort = False).append(tanpa_bayar4, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### checking\n",
    "# tanpa_bayar1.columns.to_list() == tanpa_bayar2.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanpa_bayar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "### run 39\n",
    "tanpa_bayar['Order #'] = tanpa_bayar['IDOrder'].astype(str).str.strip().str.replace('.0', '', regex = False)\n",
    "tanpa_bayar['Amount'] = pd.to_numeric(tanpa_bayar[617].astype(str).str.replace('.00 CR','', regex = False).str.replace('.00','', regex = False).str.replace(',','', regex = False).str.replace(' ','', regex = False), errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "cancel['Id  Order lama'] = cancel['Id  Order lama'].astype(str).str.strip()\n",
    "\n",
    "tanpa_bayar_reorder = tanpa_bayar.merge(cancel.drop_duplicates('Id  Order lama'), how = 'left', left_on = 'Order #', right_on = 'Id  Order lama')\n",
    "indeks = tanpa_bayar_reorder[tanpa_bayar_reorder['Id  Order lama'].notnull()].index.to_list()\n",
    "tanpa_bayar['Order #'][indeks] = tanpa_bayar_reorder['Id Order Baru'][indeks]\n",
    "\n",
    "nutrimart_tanpa_bayar = nutrimart_aft_transmandiri[nutrimart_aft_transmandiri['Order #'].isin(tanpa_bayar['Order #'].astype(str))]\n",
    "non_tanpa_bayar = nutrimart_aft_transmandiri[~nutrimart_aft_transmandiri['Order #'].isin(tanpa_bayar['Order #'].astype(str))]\n",
    "\n",
    "nutrimart_tanpa_bayar['Amount'] = 0\n",
    "nutrimart_tanpa_bayar['Total Produk'] = 0\n",
    "nutrimart_tanpa_bayar['Payment Fee'] = 0\n",
    "nutrimart_tanpa_bayar['FullFee'] = 0\n",
    "\n",
    "nutrimart_aft_tanpa_bayar = nutrimart_tanpa_bayar.append(non_tanpa_bayar, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "### run 39.1\n",
    "### subs timo isi amount pake value dari sheet subscription\n",
    "subs2 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2022 (New Format).xlsx', sheet_name = 'Subscription')\n",
    "subs3 = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2023.xlsx', sheet_name = 'Subscription')\n",
    "## cleaning subs3\n",
    "temp=subs3[subs3['SUBTOTAL BACKEND'].str.contains('RP',case=False,na=False)]\n",
    "temp['SUBTOTAL BACKEND']=temp['SUBTOTAL BACKEND'].str.replace('Rp. ','')\n",
    "temp['SUBTOTAL BACKEND']=temp['SUBTOTAL BACKEND'].str.replace(',','')\n",
    "temp['SUBTOTAL BACKEND']=temp['SUBTOTAL BACKEND'].astype(float).astype(int)\n",
    "subs3clean=subs3[~subs3['SUBTOTAL BACKEND'].str.contains('RP',case=False,na=False)]\n",
    "\n",
    "subs=subs2.append(subs3clean).append(temp)\n",
    "\n",
    "subs['Order #']=subs['ID ORDER'].fillna(0).astype(int).astype(str)\n",
    "subs=subs[subs['SUBTOTAL BACKEND'].notnull()]\n",
    "nutrimart_subs=nutrimart_aft_tanpa_bayar[nutrimart_aft_tanpa_bayar['Order #'].isin(subs['Order #'].unique())]\n",
    "nutrimart_non_subs=nutrimart_aft_tanpa_bayar[~nutrimart_aft_tanpa_bayar['Order #'].isin(subs['Order #'].unique())]\n",
    "\n",
    "nutrimart_subs_total_per_order=nutrimart_subs[nutrimart_subs['Bundle Name'].isnull()].groupby('Order #')[['Total Net Before PPN']].sum().reset_index().rename(columns={'Total Net Before PPN':'total_per_order'})\n",
    "\n",
    "nutrimart_subs_merge=nutrimart_subs.merge(subs[['Order #','SUBTOTAL BACKEND']].drop_duplicates()).merge(nutrimart_subs_total_per_order)\n",
    "\n",
    "nutrimart_subs_merge['Amount subs']=nutrimart_subs_merge['Total Net Before PPN']*nutrimart_subs_merge['SUBTOTAL BACKEND']/nutrimart_subs_merge['total_per_order']\n",
    "print(len(nutrimart_subs_merge)==len(nutrimart_subs))\n",
    "nutrimart_subs_merge=nutrimart_subs_merge.rename(columns={'Amount Subs':'Amount'})[nutrimart_aft_tanpa_bayar.columns]\n",
    "\n",
    "# nutrimart_subs_merge[['Order #','Real Nama Produk','Total Net Before PPN','SUBTOTAL BACKEND','total_per_order','Amount subs']].sort_values('Order #').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 39.2\n",
    "nutrimart_aft_subs = nutrimart_subs_merge.append(nutrimart_non_subs, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 39.3\n",
    "nutrimart_aft_tanpa_bayar=nutrimart_aft_subs.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 40\n",
    "switch = pd.read_excel(r'Settlement Project\\Nutrimart/Settlement/Transaksi Nutrimart 2022 (New Format).xlsx', sheet_name = 'Switching Channel')\n",
    "switch = switch.rename(columns = {'ID Order' : 'IDOrder'})\n",
    "switch['Source'] = '2022'\n",
    "\n",
    "switch['Order #'] = switch['IDOrder'].astype(str).str.strip().str.replace('.0', '', regex = False)\n",
    "switch['Amount'] = pd.to_numeric(switch['Amount'].astype(str).str.replace('.00 CR','', regex = False).str.replace('.00','', regex = False).str.replace(',','', regex = False).str.replace(' ','', regex = False), errors = 'coerce').fillna(0).astype(int)\n",
    "\n",
    "nutrimart_switch = nutrimart_aft_tanpa_bayar[nutrimart_aft_tanpa_bayar['Order #'].isin(switch['Order #'].astype(str))]\n",
    "non_switch = nutrimart_aft_tanpa_bayar[~nutrimart_aft_tanpa_bayar['Order #'].isin(switch['Order #'].astype(str))]\n",
    "\n",
    "nutrimart_switch = nutrimart_switch.drop(['Amount'], axis = 1)\n",
    "\n",
    "nutrimart_real = nutrimart_switch[nutrimart_switch['Bundle Name'].isnull()]\n",
    "nutrimart_bundle = nutrimart_switch[nutrimart_switch['Bundle Name'].notnull()]\n",
    "\n",
    "nutrimart_real['Order #'] = nutrimart_real['Order #'].astype(str)\n",
    "switch['Order #'] = switch['Order #'].astype(str)\n",
    "switch_short = switch[['Order #', 'Amount']].drop_duplicates('Order #')\n",
    "\n",
    "nutrimart_switch = nutrimart_real.merge(switch_short, how = 'left', on = 'Order #')\n",
    "nutrimart_switch['Amount'] = nutrimart_switch['Amount'].fillna(0) * nutrimart_switch['Total Net Before PPN']/nutrimart_switch.groupby(['Order #'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_switch['Payment Fee'] = 0\n",
    "\n",
    "indeks = nutrimart_switch[nutrimart_switch['Paid'].isin(['Refund', 'Cancel'])].index.to_list()\n",
    "nutrimart_switch['Amount'][indeks] = 0\n",
    "nutrimart_switch['Payment Fee'][indeks] = 0\n",
    "\n",
    "bundle_merge = nutrimart_bundle.merge(nutrimart_switch[['Order #', 'Product Name','Amount', 'Payment Fee']].drop_duplicates(['Order #', 'Product Name']), how = 'left', \n",
    "                                 left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "bundle_merge = bundle_merge.rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "bundle_merge = bundle_merge.drop('Product Name_y', axis = 1)\n",
    "\n",
    "bundle_merge['Amount'] = bundle_merge['Amount'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "# bundle_merge['Payment Fee'] = bundle_merge['Payment Fee'].fillna(0) * bundle_merge['Total Net Before PPN']/bundle_merge.groupby(['Order #', 'Bundle Name'])['Total Net Before PPN'].transform('sum')\n",
    "\n",
    "nutrimart_switch = nutrimart_switch.append(bundle_merge, ignore_index = True, sort = False)\n",
    "\n",
    "nutrimart_switch['Total Produk'] = pd.to_numeric(nutrimart_switch['Amount']).fillna(0).astype('int64')\n",
    "\n",
    "nutrimart_aft_switch = nutrimart_switch.append(non_switch, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalize Status and Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "### run 41\n",
    "nutrimart_payment = nutrimart_aft_tanpa_bayar.copy()\n",
    "\n",
    "indeks = nutrimart_payment[nutrimart_payment['Order #'].isin(cancel['Id  Order lama'].unique())].index.to_list()\n",
    "nutrimart_payment['Paid'][indeks] = 'Cancel'\n",
    "\n",
    "indeks = nutrimart_payment[nutrimart_payment['Order #'].isin(refund['Id  Order lama'].unique())].index.to_list()\n",
    "nutrimart_payment['Paid'][indeks] = 'Cancel'\n",
    "\n",
    "orders = nutrimart_payment[\n",
    "    (\n",
    "        (nutrimart_payment['Order #'].isin(midtrans['Order #'])) |\n",
    "        (nutrimart_payment['Order #'].isin(ovo['Order #'])) |\n",
    "        (nutrimart_payment['Order #'].isin(cod['Order #'])) |\n",
    "        (nutrimart_payment['Order #'].isin(transman['Order #'])) | \n",
    "        (nutrimart_payment['Order #'].isin(transmandiri['Order #'])) |\n",
    "        (nutrimart_payment['Order #'].isin(tanpa_bayar['Order #'])) |\n",
    "        (nutrimart_payment['Order #'].isin(switch['Order #']))|\n",
    "        (nutrimart_payment['Order #'].isin(subs['Order #'])) |\n",
    "        (nutrimart_payment['Order #'].isin(reorder)) \n",
    "    ) & \n",
    "    (~nutrimart_payment['Paid'].isin(['Refund', 'Cancel']))\n",
    "]['Order #'].unique()\n",
    "\n",
    "indeks = nutrimart_payment[nutrimart_payment['Order #'].isin(orders)].index.to_list()\n",
    "nutrimart_payment['Paid'][indeks] = 'Paid'\n",
    "nutrimart_payment['Paid'] = nutrimart_payment['Paid'].fillna('Unpaid')\n",
    "\n",
    "status_cancel = pd.read_excel(r'Settlement Project\\Nutrimart/Transaksi Nutrimart 2021 (New Format).xlsx', sheet_name = 'Transaksi cancel')\n",
    "\n",
    "indeks = nutrimart_payment[nutrimart_payment['Order #'].astype(str).isin(status_cancel['Order #'].astype(str).unique())].index.to_list()\n",
    "nutrimart_payment['Paid'][indeks] = 'Cancel'\n",
    "\n",
    "indeks = nutrimart_payment[nutrimart_payment['Order #'].astype(str).isin(all_cancel['Order #'].astype(str).unique())].index.to_list()\n",
    "nutrimart_payment['Paid'][indeks] = 'Cancel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nutrimart_payment[nutrimart_payment['Order #']=='#1180']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 42\n",
    "reward = pd.DataFrame()\n",
    "\n",
    "for i in os.listdir('Settlement Project/Nutrimart/Reward/'):\n",
    "    if 'csv' in i:\n",
    "        temp = pd.read_csv('Settlement Project/Nutrimart/Reward/' + str(i))\n",
    "        reward = reward.append(temp, ignore_index = True, sort = False)\n",
    "    \n",
    "for i in os.listdir('Settlement Project/Nutrimart/Reward/'):    \n",
    "    if 'xlsx' in i:\n",
    "        temp = pd.read_excel('Settlement Project/Nutrimart/Reward/' + str(i))\n",
    "        for i in range(0,9):\n",
    "            temp = temp.rename(columns = {temp.columns.to_list()[i]: reward.columns.to_list()[i]})\n",
    "        reward = reward.append(temp, ignore_index = True, sort = False)\n",
    "        \n",
    "\n",
    "# # reward = pd.read_csv('Settlement Project/Nutrimart/data-reward-point.csv')\n",
    "# # reward1 = pd.read_csv('Settlement Project/Nutrimart/data-reward-point-from-1-okt-26-nov.csv')\n",
    "# # reward2 = pd.read_excel('Settlement Project/Nutrimart/data-reward-point-from-25-nov-7-Jan-2022.xlsx')\n",
    "\n",
    "# # reward = reward[(reward['transaction_date'] >= '2021-01-01') & (reward['transaction_date'] < '2021-10-01')]\n",
    "# # reward1 = reward1[(reward1['transaction_date'] >= '2021-10-01') & (reward1['transaction_date'] < '2021-11-25')]\n",
    "# for i in range(0,9):\n",
    "#     reward2 = reward2.rename(columns = {reward2.columns.to_list()[i]: reward.columns.to_list()[i]})\n",
    "# reward = reward.append(reward1, ignore_index = True, sort = False).append(reward2, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 43\n",
    "reward = reward.drop_duplicates(['comment_to_customer', 'balance', 'transaction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 44\n",
    "reward = reward[reward['comment_to_customer'].astype(str).str.contains('spent', case = False)]\n",
    "reward['Order #'] = reward['comment_to_customer'].astype(str).str.split('#', expand = True)[1]\n",
    "reward['Reward Amount'] = reward['balance']\n",
    "\n",
    "reward_real = nutrimart_payment[nutrimart_payment['Bundle Name'].isnull()]\n",
    "reward_bundle = nutrimart_payment[nutrimart_payment['Bundle Name'].notnull()]\n",
    "\n",
    "reward_real = reward_real.merge(reward[['Order #', 'Reward Amount']].drop_duplicates('Order #'), how = 'left', on = 'Order #')\n",
    "reward_real['Reward Amount'] = reward_real['Reward Amount'] * reward_real['Total Net']/reward_real.groupby('Order #')['Total Net'].transform('sum')\n",
    "\n",
    "reward_bundle = reward_bundle.merge(reward_real[['Order #', 'Product Name', 'Reward Amount']].drop_duplicates(['Order #', 'Product Name']), how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "reward_bundle = reward_bundle.drop('Product Name_y', axis = 1).rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "reward_bundle['Reward Amount'] =  reward_bundle['Reward Amount'] * reward_bundle['Total Net']/reward_bundle.groupby(['Order #', 'Bundle Name'])['Total Net'].transform('sum')\n",
    "\n",
    "nutrimart_aft_reward = reward_real.append(reward_bundle, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 45\n",
    "credit = pd.DataFrame()\n",
    "\n",
    "for i in os.listdir('Settlement Project/Nutrimart/Store Credit/'):\n",
    "    if 'csv' in i:\n",
    "        temp = pd.read_csv('Settlement Project/Nutrimart/Store Credit/' + str(i))\n",
    "        credit = credit.append(temp, ignore_index = True, sort = False)\n",
    "        \n",
    "for i in os.listdir('Settlement Project/Nutrimart/Store Credit/'):        \n",
    "    if 'xlsx' in i:\n",
    "        temp = pd.read_excel('Settlement Project/Nutrimart/Store Credit/' + str(i))\n",
    "        temp['Balance Change'] = pd.to_numeric(temp['Balance Change'].astype(str).str.replace('Rp.', '', regex = False).astype(str).str.replace('.00 CR','', regex = False).str.replace('.00','', regex = False).str.replace(',','', regex = False).str.replace(' ','', regex = False), errors = 'coerce').fillna(0).astype(int)\n",
    "        for i in range(0,8):\n",
    "            temp = temp.rename(columns = {temp.columns.to_list()[i]: credit.columns.to_list()[i]})\n",
    "        credit = credit.append(temp, ignore_index = True, sort = False)\n",
    "        \n",
    "credit = credit.drop_duplicates(['comment_to_customer', 'balance', 'transaction_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 46\n",
    "credit = credit[credit['comment_to_customer'].astype(str).str.contains('spent', case = False)]\n",
    "credit['Order #'] = credit['comment_to_customer'].astype(str).str.split('#', expand = True)[1]\n",
    "credit['Store Credit Amount'] = credit['balance']\n",
    "\n",
    "credit_real = nutrimart_aft_reward[nutrimart_aft_reward['Bundle Name'].isnull()]\n",
    "credit_bundle = nutrimart_aft_reward[nutrimart_aft_reward['Bundle Name'].notnull()]\n",
    "\n",
    "credit_real = credit_real.merge(credit[['Order #', 'Store Credit Amount']].drop_duplicates('Order #'), how = 'left', on = 'Order #')\n",
    "credit_real['Store Credit Amount'] = credit_real['Store Credit Amount'] * credit_real['Total Net']/credit_real.groupby('Order #')['Total Net'].transform('sum')\n",
    "\n",
    "credit_bundle = credit_bundle.merge(credit_real[['Order #', 'Product Name', 'Store Credit Amount']].drop_duplicates(['Order #', 'Product Name']), how = 'left', left_on = ['Order #', 'Bundle Name'], right_on = ['Order #', 'Product Name'])\n",
    "credit_bundle = credit_bundle.drop('Product Name_y', axis = 1).rename(columns = {'Product Name_x' : 'Product Name'})\n",
    "credit_bundle['Store Credit Amount'] =  credit_bundle['Store Credit Amount'] * credit_bundle['Total Net']/credit_bundle.groupby(['Order #', 'Bundle Name'])['Total Net'].transform('sum')\n",
    "\n",
    "nutrimart_aft_sc = credit_real.append(credit_bundle, ignore_index = True, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Order #  Total Net Before PPN\n",
      "8093   #1180             1584000.0\n",
      "8094   #1180             1620000.0\n",
      "     Order #  Total Net Before PPN\n",
      "8093   #1180             1584000.0\n",
      "8094   #1180             1620000.0\n"
     ]
    }
   ],
   "source": [
    "### run 47\n",
    "total_trx = nutrimart_aft_sc.copy()\n",
    "\n",
    "total_trx['Product ID'] = total_trx['Real SKU']\n",
    "total_trx['SO STATUS'] = total_trx['Outbound Status']\n",
    "total_trx['Warehouse Quantity'] = total_trx['Outbound Qty']\n",
    "total_trx['Total Produk Prop'] = total_trx['Total Produk']\n",
    "total_trx['Fullfee Prop'] = 0\n",
    "total_trx['Comfee Prop'] = 0\n",
    "total_trx['WH'] = 'Telkom'\n",
    "total_trx['Warehouse Origin'] = 'Telkom'\n",
    "\n",
    "# print(total_trx[total_trx['Order #']=='#1180'][['Order #','Total Net Before PPN']])\n",
    "\n",
    "# Sementara\n",
    "## total produk, dikurangin lagi shipping\n",
    "## shipping proposional\n",
    "total_trx['Total Transfer'] = total_trx['Amount']\n",
    "total_trx['Order Status_y'] = total_trx['Order Status']\n",
    "total_trx['Total Selcen'] = total_trx['Total']\n",
    "total_trx['Order Date Seller Centre'] = total_trx['True datetime']\n",
    "total_trx['Total Produk Prop'] = total_trx['Total'] + total_trx['Reward Amount'].fillna(0) + total_trx['Store Credit Amount'].fillna(0)\n",
    "\n",
    "total_trx['Total Produk Prop Adj'] = total_trx['Total Produk Prop']/1.11\n",
    "total_trx['BTL Cost'] = (total_trx['Total Produk Prop Adj']) - total_trx['Total Net Before PPN']\n",
    "total_trx['Payment Fee'] = total_trx['Payment Fee'] * (-1)\n",
    "\n",
    "\n",
    "\n",
    "## tambahan timo jan 2023\n",
    "total_trx['Shipping non prop']=total_trx['Shipping']\n",
    "total_per_order=total_trx[total_trx['Bundle Name'].isnull()].groupby('Order #')[['Total Net Before PPN']].sum().reset_index().rename(columns={'Total Net Before PPN':'total_per_order'})\n",
    "print(total_trx[total_trx['Order #']=='#1180'][['Order #','Total Net Before PPN']])\n",
    "total_trx=total_trx.merge(total_per_order,how='left',on='Order #')\n",
    "print(total_trx[total_trx['Order #']=='#1180'][['Order #','Total Net Before PPN']])\n",
    "\n",
    "total_trx['Shipping']=total_trx['Shipping non prop']*total_trx['Total Net Before PPN']/total_trx['total_per_order']\n",
    "\n",
    "# print(total_trx[total_trx['Order #']=='#1180'][['Order #','Total Net Before PPN']])\n",
    "\n",
    "total_trx_full = total_trx[['Order #',\n",
    " 'Sales Order ID',\n",
    " 'AWB',\n",
    " 'Paid Date',\n",
    " 'Order date',\n",
    " 'Week',\n",
    " 'Date',\n",
    " 'Month',\n",
    " 'Quarter',\n",
    " 'Year',\n",
    " 'Channel',\n",
    " 'SKU',\n",
    " 'Brand',\n",
    " 'Product Name',\n",
    " 'Bundle Name',\n",
    " 'Price List NFI',\n",
    " 'Qty. Invoiced',\n",
    " 'Total Net',\n",
    " 'Sub Brand',\n",
    " 'Real SKU',\n",
    " 'Real Nama Produk',\n",
    " 'Parent Item',\n",
    " 'Parent SKU',\n",
    " 'Bundle Flag',\n",
    " 'Shipping Courier',\n",
    " 'Store',\n",
    " 'True datetime',\n",
    " 'Store Type',\n",
    " 'Region Group',\n",
    " 'PL Before PPN',\n",
    " 'Total Net Before PPN',\n",
    " 'Category Baru',\n",
    " 'Exported Parent Item',\n",
    " 'Coupon Code',\n",
    " 'Payment Channel',\n",
    " 'Order Date Seller Centre',\n",
    " 'Product ID',\n",
    " 'Total Selcen',\n",
    " 'Order Status_y',\n",
    " 'Warehouse Origin',\n",
    " 'Paid',\n",
    " 'SO STATUS',\n",
    " 'WH',\n",
    " 'Warehouse Quantity',\n",
    " 'Total Transfer',\n",
    "  'Reward Amount',\n",
    "  'Store Credit Amount',\n",
    " 'Total Produk Prop',\n",
    " 'Fullfee Prop',\n",
    " 'Comfee Prop',\n",
    " 'BTL Cost',\n",
    " 'Total Produk Prop Adj',\n",
    " 'Payment Fee',\n",
    " 'Shipping',\n",
    "  'Voucher Product',\n",
    "  'Voucher Ongkir',\n",
    "  'Pemilik Budget',\n",
    "  'Cluster'\n",
    " ]]\n",
    "\n",
    "total_trx_full = total_trx_full.rename(columns = {\n",
    "    'Total Selcen' : 'Total Seller Centre', \n",
    "    'Order Status_y' : 'Order Status Seller Centre',\n",
    "    'SO STATUS' : 'Status Gudang'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_trx_full[total_trx_full['Order #']=='#1180']\n",
    "# total_per_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run 48\n",
    "total_trx_full.to_csv(r\"Settlement Project\\Backup\\Realisasi Aug 2024\\Final Result\\Before Compare/\" + 'Running Nutrimart Aug 2024.csv', index = False, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_trx_full['Year'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev.loc[prev['Bundle Name']=='Green Packing - HiLo School Chocolate Ready To...','Bundle Name']='Green Packing - HiLo School Chocolate Ready To Drink (4 tetrapack)'\n",
    "prev.loc[prev['Bundle Name']=='Green Packing - Tropicana Slim Oat Drink 190 m...','Bundle Name']='Green Packing - Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs'\n",
    "prev.loc[prev['Bundle Name']=='Green Packing - 4 pack - NutriSari RTD Squeeze...','Bundle Name']='Green Packing - 4 pack - NutriSari RTD Squeezed Orange 200 ml'\n",
    "prev.loc[prev['Bundle Name']=='Green Packing - Hilo Teen Chocolate Ready To D...','Bundle Name']='Green Packing - Hilo Teen Chocolate Ready To Drink Susu [4 pcs]'\n",
    "prev.loc[prev['Bundle Name']=='Green Packing - Tropicana Slim Minyak Kanola 9...','Bundle Name']='Green Packing - Tropicana Slim Minyak Kanola 946ml'\n",
    "prev.loc[prev['Bundle Name']=='Green Packing - L-Men Hi Protein 2 Go Chocolat...','Bundle Name']='Green Packing - L-Men Hi Protein 2 Go Chocolate x 4 pcs'\n",
    "prev.loc[prev['Bundle Name']=='Paket NutriSari 35 Rasa','Bundle Name']='Paket NutriSari Banyak Rasa!  35 Rasa NutriSari (105 Sch) Hampers Box'\n",
    "# prev = pd.read_csv(\"D:\\Backup\\Backup 26 Mei\\Settlement Project Backup\\Realisasi Januari 2022\\Final Result\\Running Nutrimart Jan Jan 2022.csv\", sep = ';')\n",
    "prev.loc[prev['Bundle Name']=='Paket Sobat Melek Lokalate (Segitiga)','Bundle Name']='Paket Melek Lokalate 5 Rasa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timotius.giovandi\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Month   Paid    Paid July\n",
       "August  Paid    NaN          146\n",
       "        Unpaid  NaN           94\n",
       "July    Paid    Unpaid         4\n",
       "                NaN          103\n",
       "        Unpaid  NaN          100\n",
       "Name: Order #, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run 49\n",
    "import pandas as pd\n",
    "\n",
    "prev = pd.read_csv(r\"D:\\6. settlement\\Code\\Settlement Project\\Backup\\Realisasi Jul 2024\\Final Result\\Raw Unpivoted\\CSV\\Running Nutrimart Jan 23 - Jul 24.csv\", sep = ';')\n",
    "prev_month = 'July'\n",
    "prev = prev.rename(columns = {'Paid' : 'Paid ' + prev_month})\n",
    "current = total_trx_full.copy()\n",
    "current.loc[current['Bundle Name']=='Green Packing - HiLo School Chocolate Ready To...','Bundle Name']='Green Packing - HiLo School Chocolate Ready To Drink (4 tetrapack)'\n",
    "current.loc[current['Bundle Name']=='Green Packing - Tropicana Slim Oat Drink 190 m...','Bundle Name']='Green Packing - Tropicana Slim Oat Drink 190 ml (RTD) x 4 pcs'\n",
    "current.loc[current['Bundle Name']=='Green Packing - 4 pack - NutriSari RTD Squeeze...','Bundle Name']='Green Packing - 4 pack - NutriSari RTD Squeezed Orange 200 ml'\n",
    "current.loc[current['Bundle Name']=='Green Packing - Hilo Teen Chocolate Ready To D...','Bundle Name']='Green Packing - Hilo Teen Chocolate Ready To Drink Susu [4 pcs]'\n",
    "current.loc[current['Bundle Name']=='Green Packing - Tropicana Slim Minyak Kanola 9...','Bundle Name']='Green Packing - Tropicana Slim Minyak Kanola 946ml'\n",
    "current.loc[current['Bundle Name']=='Green Packing - L-Men Hi Protein 2 Go Chocolat...','Bundle Name']='Green Packing - L-Men Hi Protein 2 Go Chocolate x 4 pcs'\n",
    "current.loc[current['Bundle Name']=='Paket NutriSari 35 Rasa','Bundle Name']='Paket NutriSari Banyak Rasa!  35 Rasa NutriSari (105 Sch) Hampers Box'\n",
    "# current = pd.read_csv(\"D:\\Backup\\Backup 26 Mei\\Settlement Project Backup\\Realisasi Januari 2022\\Final Result\\Running Nutrimart Jan Jan 2022.csv\", sep = ';')\n",
    "current.loc[current['Bundle Name']=='Paket Sobat Melek Lokalate (Segitiga)','Bundle Name']='Paket Melek Lokalate 5 Rasa'\n",
    "\n",
    "prev['Order #'] = prev['Order #'].astype(str)\n",
    "prev['Real SKU'] = prev['Real SKU'].astype(str)\n",
    "current['Order #'] = current['Order #'].astype(str)\n",
    "current['Real SKU'] = current['Real SKU'].astype(str)\n",
    "\n",
    "merged = current.merge(prev[['Order #','Real SKU', 'Paid ' + prev_month, 'Bundle Name']].drop_duplicates(['Order #', 'Real SKU', 'Bundle Name']), how = 'left', on = ['Order #', 'Real SKU', 'Bundle Name'])\n",
    "import numpy as np\n",
    "\n",
    "merged['Paid Beda'] = np.nan\n",
    "\n",
    "merged.loc[(merged['Paid']=='Unpaid')&(merged['Paid ' + prev_month]=='Cancel'),'Paid']='Cancel'\n",
    "\n",
    "indeks = merged[merged['Paid'] != merged['Paid ' + prev_month]].index.to_list()\n",
    "merged['Paid Beda'][indeks] = 'Beda'\n",
    "\n",
    "merged['Paid Beda'] = merged['Paid Beda'].fillna('Sama')\n",
    "# merged[merged['Paid Beda'] == 'Beda'][['Order #','Brand','Real SKU','Month', 'Paid_x', 'Paid_y', 'Paid Beda']]\n",
    "merged[merged['Paid Beda'] == 'Beda'].groupby(['Month', 'Paid', 'Paid ' + prev_month],dropna=False)['Order #'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run 50\n",
    "merged = merged.rename(columns = {'Paid' : 'Paid August'})\n",
    "# merged.to_csv('D:\\settlement\\Code\\Settlement Project\\Backup\\Realisasi Juni 2022\\Final Result\\Raw Unpivoted\\CSV\\Running Nutrimart Jan 21 - Juni 22.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run 51\n",
    "fincol=pd.read_excel(\"Settlement Project\\Backup\\Realisasi Apr 2023\\Final Result\\Raw Unpivoted\\Excel\\Running Nutrimart Jan 21 - Apr 23.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run 52\n",
    "\n",
    "fincol=fincol.rename(columns={'Paid April':'Paid August'})\n",
    "fincol=fincol.rename(columns={'Paid March':'Paid July'})\n",
    "# fincol=fincol.rename(columns={'Paid April':'Paid May'})\n",
    "# fincol=fincol.rename(columns={'Paid March':'Paid January'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel sdh\n"
     ]
    }
   ],
   "source": [
    "## run 53\n",
    "merged[fincol.columns].to_excel('Settlement Project\\Backup\\Realisasi Aug 2024\\Final Result\\Raw Unpivoted\\Excel\\Running Nutrimart Jan 23 - Aug 24.xlsx', index = False)\n",
    "print('excel sdh')#.columns\n",
    "merged[fincol.columns].to_csv('Settlement Project\\Backup\\Realisasi Aug 2024\\Final Result\\Raw Unpivoted\\CSV\\Running Nutrimart Jan 23 - Aug 24.csv', sep = ';', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged[['Order #', 'Real SKU', 'Bundle Name']].duplicated(keep = False)][['Order #', 'Real SKU', 'Bundle Name', 'Product Name', 'Qty. Invoiced', 'Month', 'Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[data_all['Order #'] == '1000097863'][['Order #', 'Real SKU', 'Bundle Name', 'Product Name', 'Qty. Invoiced', 'Month', 'Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrimart_payment[nutrimart_payment['Order #'] == '1000082563']['Payment Channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'1000084752' in cancel['Id  Order lama'].astype(str).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'google' from 'google' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2816\\1983120052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnum_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msearch_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This is my query\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'google' from 'google' (unknown location)"
     ]
    }
   ],
   "source": [
    "from google import google\n",
    "num_page = 3\n",
    "search_results = google.search(\"This is my query\", num_page)\n",
    "for result in search_results:\n",
    "    print(result.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google\n",
      "  Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from google) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from beautifulsoup4->google) (2.0.1)\n",
      "Installing collected packages: google\n",
      "Successfully installed google-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yqt5-sip (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\users\\andra.miftah\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\andra.miftah\\AppData\\Local\\Continuum\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andra.miftah\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(r'D:\\Backup\\Backup 26 Mei\\Settlement Project Backup\\Realisasi Februari 2022\\Final Result\\Running Nutrimart Jan 21 - Feb 22.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[(data['Year'] == 2022) & (data['Pemilik Budget'].isnull()) & (data['Coupon Code'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.read_excel(r\"Settlement Project\\Nutrimart\\voucher.xlsx\", sheet_name = 'Area')\n",
    "cluster = pd.read_excel(r\"Settlement Project\\Nutrimart\\voucher.xlsx\", sheet_name = 'Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_coupon = temp[['Coupon Code']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andra.miftah\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\andra.miftah\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\andra.miftah\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\andra.miftah\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "temp_coupon['Coupon Code'] = temp_coupon['Coupon Code'].astype(str).str.upper()\n",
    "temp_coupon['Dept'] = np.nan\n",
    "temp_coupon['Cluster Code'] = np.nan\n",
    "\n",
    "temp_coupon['Original Coupon Code'] = temp_coupon['Coupon Code'].copy()\n",
    "\n",
    "for i in area['Kode Area']:\n",
    "    indeks = temp_coupon[temp_coupon['Coupon Code'].astype(str).str.upper().str.contains('^' + str(i), regex = True)].index.to_list()\n",
    "    if len(indeks) > 0 :\n",
    "        temp_coupon['Dept'][indeks] = 'Homdel'\n",
    "        temp_coupon['Coupon Code'][indeks] = temp_coupon['Coupon Code'][indeks].astype(str).str.upper().str.replace('^' + str(i), '', regex = True)\n",
    "        temp_coupon['Cluster Code'][indeks] = temp_coupon['Coupon Code'][indeks].astype(str).str[0]\n",
    "        indeks_2 = temp_coupon[~(temp_coupon['Cluster Code'].astype(str).str.isnumeric()) & (temp_coupon.index.isin(indeks))].index.to_list()\n",
    "        temp_coupon['Cluster Code'][indeks_2] = temp_coupon['Coupon Code'][indeks_2].astype(str).str[:3]\n",
    "        \n",
    "temp_coupon_null = temp_coupon[temp_coupon['Dept'].isnull()].copy()\n",
    "temp_coupon_null['Dept'] = temp_coupon_null['Coupon Code'].astype(str).str[:3]\n",
    "temp_coupon_null['Cluster Code'] = temp_coupon_null['Coupon Code'].astype(str).str[3:4]\n",
    "\n",
    "indeks_3 = temp_coupon_null[~(temp_coupon_null['Cluster Code'].astype(str).str.isnumeric())].index.to_list()\n",
    "temp_coupon_null['Cluster Code'][indeks_3] = temp_coupon_null['Coupon Code'][indeks_3].astype(str).str[3:6]\n",
    "\n",
    "temp_coupon['Dept'][temp_coupon_null.index] = temp_coupon_null['Dept']\n",
    "temp_coupon['Cluster Code'][temp_coupon_null.index] = temp_coupon_null['Cluster Code']\n",
    "\n",
    "cluster['Cluster Code'] = cluster['Cluster Code'].astype(str)\n",
    "temp_coupon['Cluster Code'] = temp_coupon['Cluster Code'].astype(str)\n",
    "\n",
    "temp_coupon = temp_coupon.merge(cluster, how = 'left', on = 'Cluster Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_coupon.groupby('Dept')['Original Coupon Code'].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_coupon[temp_coupon['Cluster'].isnull()].drop_duplicates('Cluster Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_coupon[temp_coupon['Cluster'].isnull()].drop_duplicates('Cluster Code').to_excel(r'Coupon Tes Algo.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>customer_email</th>\n",
       "      <th>comment_to_customer</th>\n",
       "      <th>comment_to_admin</th>\n",
       "      <th>balance</th>\n",
       "      <th>current_balance</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>Type</th>\n",
       "      <th>Website</th>\n",
       "      <th>Customer Notified</th>\n",
       "      <th>Created By</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1342</td>\n",
       "      <td>Rosalina Gunawan</td>\n",
       "      <td>gunawanrosalina1gmail.com</td>\n",
       "      <td>Spent Store Credit on order#1000098491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-40000</td>\n",
       "      <td>Rp. 0.00</td>\n",
       "      <td>Jan 26, 2022 9:55:34 PM</td>\n",
       "      <td>Store Credit used in order</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1341</td>\n",
       "      <td>Yohanes Danniel</td>\n",
       "      <td>dansapyoyahoo.com</td>\n",
       "      <td>Cashback : \"Dec 2021 - Recurring Customers Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40000</td>\n",
       "      <td>Rp. 40,000.00</td>\n",
       "      <td>Jan 26, 2022 5:14:50 PM</td>\n",
       "      <td>Balance adjusted by admin</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1340</td>\n",
       "      <td>Susanna Susanna</td>\n",
       "      <td>susanna.agushotmail.com</td>\n",
       "      <td>Cashback : \"Dec 2021 - Recurring Customers Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40000</td>\n",
       "      <td>Rp. 40,000.00</td>\n",
       "      <td>Jan 26, 2022 5:14:49 PM</td>\n",
       "      <td>Balance adjusted by admin</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1339</td>\n",
       "      <td>Endang Sri Murtini</td>\n",
       "      <td>endangmurtini26gmail.com</td>\n",
       "      <td>Cashback : \"Dec 2021 - Recurring Customers Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24200</td>\n",
       "      <td>Rp. 24,200.00</td>\n",
       "      <td>Jan 26, 2022 5:14:48 PM</td>\n",
       "      <td>Balance adjusted by admin</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1338</td>\n",
       "      <td>Sanastri Tadjudin</td>\n",
       "      <td>sanastri.tgmail.com</td>\n",
       "      <td>Cashback : \"Dec 2021 - Recurring Customers Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36969</td>\n",
       "      <td>Rp. 36,969.95</td>\n",
       "      <td>Jan 26, 2022 5:14:47 PM</td>\n",
       "      <td>Balance adjusted by admin</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1193</td>\n",
       "      <td>Dessy Arsita</td>\n",
       "      <td>dearta810gmail.com</td>\n",
       "      <td>Cashback : \"Dec 2021 - Recurring Customers Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33200</td>\n",
       "      <td>Rp. 33,200.00</td>\n",
       "      <td>Dec 11, 2021 5:14:19 PM</td>\n",
       "      <td>Balance adjusted by admin</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1192</td>\n",
       "      <td>Bayu Ismadi</td>\n",
       "      <td>emailcibinonggmail.com</td>\n",
       "      <td>Cashback : \"Dec 2021 - Recurring Customers Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40000</td>\n",
       "      <td>Rp. 40,000.00</td>\n",
       "      <td>Dec 9, 2021 5:14:35 PM</td>\n",
       "      <td>Balance adjusted by admin</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1191</td>\n",
       "      <td>(LOYALTY) Arum Lestariningtyas</td>\n",
       "      <td>b_arumyahoo.co.uk</td>\n",
       "      <td>Cashback : \"Dec 2021 - Recurring Customers Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35600</td>\n",
       "      <td>Rp. 185,600.00</td>\n",
       "      <td>Dec 9, 2021 5:14:34 PM</td>\n",
       "      <td>Balance adjusted by admin</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1190</td>\n",
       "      <td>Ambali Balli</td>\n",
       "      <td>balibalbalgmail.com</td>\n",
       "      <td>Cashback : \"Dec 2021 - Recurring Customers Cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6850</td>\n",
       "      <td>Rp. 6,850.00</td>\n",
       "      <td>Dec 9, 2021 5:14:32 PM</td>\n",
       "      <td>Balance adjusted by admin</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1189</td>\n",
       "      <td>Ambali Balli</td>\n",
       "      <td>balibalbalgmail.com</td>\n",
       "      <td>Spent Store Credit on order#1000096994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-40000</td>\n",
       "      <td>Rp. 0.00</td>\n",
       "      <td>Dec 9, 2021 9:39:58 AM</td>\n",
       "      <td>Store Credit used in order</td>\n",
       "      <td>Main Website</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id                   customer_name             customer_email  \\\n",
       "0           1342                Rosalina Gunawan  gunawanrosalina1gmail.com   \n",
       "1           1341                 Yohanes Danniel          dansapyoyahoo.com   \n",
       "2           1340                 Susanna Susanna    susanna.agushotmail.com   \n",
       "3           1339              Endang Sri Murtini   endangmurtini26gmail.com   \n",
       "4           1338               Sanastri Tadjudin        sanastri.tgmail.com   \n",
       "..           ...                             ...                        ...   \n",
       "148         1193                    Dessy Arsita         dearta810gmail.com   \n",
       "149         1192                     Bayu Ismadi     emailcibinonggmail.com   \n",
       "150         1191  (LOYALTY) Arum Lestariningtyas          b_arumyahoo.co.uk   \n",
       "151         1190                    Ambali Balli        balibalbalgmail.com   \n",
       "152         1189                    Ambali Balli        balibalbalgmail.com   \n",
       "\n",
       "                                   comment_to_customer comment_to_admin  \\\n",
       "0              Spent Store Credit on order#1000098491              NaN   \n",
       "1    Cashback : \"Dec 2021 - Recurring Customers Cas...              NaN   \n",
       "2    Cashback : \"Dec 2021 - Recurring Customers Cas...              NaN   \n",
       "3    Cashback : \"Dec 2021 - Recurring Customers Cas...              NaN   \n",
       "4    Cashback : \"Dec 2021 - Recurring Customers Cas...              NaN   \n",
       "..                                                 ...              ...   \n",
       "148  Cashback : \"Dec 2021 - Recurring Customers Cas...              NaN   \n",
       "149  Cashback : \"Dec 2021 - Recurring Customers Cas...              NaN   \n",
       "150  Cashback : \"Dec 2021 - Recurring Customers Cas...              NaN   \n",
       "151  Cashback : \"Dec 2021 - Recurring Customers Cas...              NaN   \n",
       "152            Spent Store Credit on order#1000096994              NaN   \n",
       "\n",
       "     balance current_balance         transaction_date  \\\n",
       "0     -40000        Rp. 0.00  Jan 26, 2022 9:55:34 PM   \n",
       "1      40000   Rp. 40,000.00  Jan 26, 2022 5:14:50 PM   \n",
       "2      40000   Rp. 40,000.00  Jan 26, 2022 5:14:49 PM   \n",
       "3      24200   Rp. 24,200.00  Jan 26, 2022 5:14:48 PM   \n",
       "4      36969   Rp. 36,969.95  Jan 26, 2022 5:14:47 PM   \n",
       "..       ...             ...                      ...   \n",
       "148    33200   Rp. 33,200.00  Dec 11, 2021 5:14:19 PM   \n",
       "149    40000   Rp. 40,000.00   Dec 9, 2021 5:14:35 PM   \n",
       "150    35600  Rp. 185,600.00   Dec 9, 2021 5:14:34 PM   \n",
       "151     6850    Rp. 6,850.00   Dec 9, 2021 5:14:32 PM   \n",
       "152   -40000        Rp. 0.00   Dec 9, 2021 9:39:58 AM   \n",
       "\n",
       "                           Type       Website Customer Notified Created By  \n",
       "0    Store Credit used in order  Main Website               Yes        NaN  \n",
       "1     Balance adjusted by admin  Main Website               Yes        NaN  \n",
       "2     Balance adjusted by admin  Main Website               Yes        NaN  \n",
       "3     Balance adjusted by admin  Main Website               Yes        NaN  \n",
       "4     Balance adjusted by admin  Main Website               Yes        NaN  \n",
       "..                          ...           ...               ...        ...  \n",
       "148   Balance adjusted by admin  Main Website               Yes        NaN  \n",
       "149   Balance adjusted by admin  Main Website               Yes        NaN  \n",
       "150   Balance adjusted by admin  Main Website               Yes        NaN  \n",
       "151   Balance adjusted by admin  Main Website               Yes        NaN  \n",
       "152  Store Credit used in order  Main Website               Yes        NaN  \n",
       "\n",
       "[153 rows x 12 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['customer_email']=temp['customer_email'].str.replace('@','')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
